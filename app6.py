import streamlit as st

# å°†è¿™è¡Œç§»åˆ°æ‰€æœ‰ st å‘½ä»¤ä¹‹å‰
st.set_page_config(page_title="å¤æ–°Vis-æ•°æ®æ–°é—»å¤šæ™ºèƒ½ä½“å·¥ä½œæµ", layout="wide")

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI
import os
from dotenv import load_dotenv
import json
import logging
from typing import Dict, Tuple, Optional, List, Any
import functools
import time
import concurrent.futures
from dataclasses import dataclass
import re  # Import the regular expression module
import requests
import asyncio
from crawl4ai import AsyncWebCrawler
from bs4 import BeautifulSoup
from pyecharts import options as opts
from pyecharts.charts import Bar, Pie, Line, Scatter, HeatMap, Tree, Sunburst
from pyecharts.charts import TreeMap, Boxplot
from pyecharts.globals import ThemeType
from streamlit_echarts import st_pyecharts
import numpy as np  # ç¡®ä¿å¯¼å…¥numpyç”¨äºç›´æ–¹å›¾è®¡ç®—
from io import BytesIO, StringIO
from docx import Document
from docx.shared import Inches
import base64

def search_with_tavily(query):
    """ä½¿ç”¨ Tavily API æœç´¢ç›¸å…³ä¿¡æ¯"""
    try:
        TAVILY_API_KEY = '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'
        TAVILY_API_URL = 'https://api.tavily.com/search'
        
        data = {
            "api_key": TAVILY_API_KEY,
            "query": query,
            "search_depth": "basic",
            "max_results": 5,
            "language": "zh"
        }
        
        response = requests.post(TAVILY_API_URL, json=data)
        response.raise_for_status()
        result = response.json()
        
        # æå–æœ€å¤š3ä¸ªæœç´¢ç»“æœ
        if 'results' in result:
            return [
                {
                    'title': item.get('title', ''),
                    'content': item.get('content', '')[:500],
                    'url': item.get('url', '')
                }
                for item in result['results'][:3]
            ]
        return []
    except Exception as e:
        logger.error(f"Tavily API é”™è¯¯: {str(e)}")
        return []

# æ–°å¢æ•°æ®æ”¶é›†æ™ºèƒ½ä½“ç±»
class DataCollectionAgent:
    """æ•°æ®æ”¶é›†æ™ºèƒ½ä½“ï¼Œè´Ÿè´£å¤šç»´åº¦æ•°æ®æ”¶é›†å’Œæ•´åˆ"""
    
    def __init__(self, client):
        self.client = client
        self.tavily_api_key = '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'
        self.tavily_url = 'https://api.tavily.com/search'
    
    def collect_multi_dimensional_data(self, directions: List[str], topic: str) -> Dict[str, Any]:
        """å¤šç»´åº¦æ•°æ®æ”¶é›†"""
        results = {
            'structured_data': [],
            'text_data': [],
            'collection_summary': {},
            'failed_directions': []
        }
        
        progress = st.progress(0)
        status_text = st.empty()
        
        for i, direction in enumerate(directions):
            status_text.text(f"æ­£åœ¨æ”¶é›†: {direction} ({i+1}/{len(directions)})")
            
            try:
                # ä½¿ç”¨Tavilyæœç´¢ç›¸å…³ä¿¡æ¯
                search_results = self._search_with_tavily_enhanced(direction, topic)
                
                if search_results:
                    # å¯¹æ¯ä¸ªæœç´¢ç»“æœè¿›è¡Œæ™ºèƒ½åˆ†æå’Œç»“æ„åŒ–
                    for result in search_results[:3]:  # é™åˆ¶æ¯ä¸ªæ–¹å‘æœ€å¤šå¤„ç†3ä¸ªç»“æœ
                        structured_data = self._intelligent_structurize(result, direction, topic)
                        
                        if structured_data is not None and not structured_data.empty:
                            structured_data['data_direction'] = direction
                            structured_data['source_url'] = result.get('url', '')
                            results['structured_data'].append(structured_data)
                        else:
                            # å¦‚æœæ— æ³•ç»“æ„åŒ–ï¼Œä¿å­˜ä¸ºæ–‡æœ¬æ•°æ®
                            results['text_data'].append({
                                'direction': direction,
                                'content': result.get('content', ''),
                                'url': result.get('url', ''),
                                'title': result.get('title', '')
                            })
                    
                    results['collection_summary'][direction] = f"æˆåŠŸæ”¶é›†åˆ° {len(search_results)} æ¡ç›¸å…³ä¿¡æ¯"
                else:
                    results['failed_directions'].append(direction)
                    results['collection_summary'][direction] = "æœªæ‰¾åˆ°ç›¸å…³æ•°æ®"
                    
            except Exception as e:
                results['failed_directions'].append(direction)
                results['collection_summary'][direction] = f"æ”¶é›†å¤±è´¥: {str(e)}"
            
            progress.progress((i + 1) / len(directions))
        
        status_text.text("æ•°æ®æ”¶é›†å®Œæˆ")
        progress.empty()
        status_text.empty()
        
        return results
    
    def _search_with_tavily_enhanced(self, query: str, topic: str) -> List[Dict]:
        """å¢å¼ºç‰ˆTavilyæœç´¢"""
        try:
            # ç»“åˆé€‰é¢˜å’Œå…·ä½“æ–¹å‘è¿›è¡Œæœç´¢ï¼Œå¹¶å°è¯•é™å®šå¸¸è§æ•°æ®æ–‡ä»¶ç±»å‹
            enhanced_query = (
                f"{topic} {query} æ•°æ® ç»Ÿè®¡ æŠ¥å‘Š filetype:csv OR filetype:xls OR filetype:xlsx OR filetype:pdf"
            )

            data = {
                "api_key": self.tavily_api_key,
                "query": enhanced_query,
                "search_depth": "advanced",  # ä½¿ç”¨é«˜çº§æœç´¢
                "max_results": 8,
                "language": "zh",
                "include_domains": ["gov.cn", "stats.gov.cn", "xinhuanet.com", "people.com.cn"],  # ä¼˜å…ˆæƒå¨æ¥æº
                "exclude_domains": ["baidu.com", "so.com"]  # æ’é™¤æœç´¢å¼•æ“é¡µé¢
            }
            
            response = requests.post(self.tavily_url, json=data, timeout=30)
            response.raise_for_status()
            result = response.json()
            
            if 'results' in result:
                results = result['results']
                # ç®€å•æ ¹æ®æ ‡é¢˜åŒ¹é…é€‰é¢˜æˆ–æ–¹å‘å…³é”®è¯ä»¥æå‡ç›¸å…³åº¦
                filtered = [
                    r for r in results
                    if topic.lower() in r.get('title', '').lower()
                    or query.lower() in r.get('title', '').lower()
                ]
                return filtered if filtered else results
            return []
            
        except Exception as e:
            logger.error(f"Enhanced Tavily search error: {str(e)}")
            return []
    
    def _intelligent_structurize(self, search_result: Dict, direction: str, topic: str) -> Optional[pd.DataFrame]:
        """æ™ºèƒ½ç»“æ„åŒ–å¤„ç† - ä½¿ç”¨ä¸¤é˜¶æ®µæ¨ç†ï¼šGLM-4-PLUSç­›é€‰ + GLM-Z1-AIRXæ·±åº¦æ¨ç†"""
        try:
            content = search_result.get('content', '')
            title = search_result.get('title', '')
            url = search_result.get('url', '')
            
            # å¦‚æœå†…å®¹å¤ªçŸ­ï¼Œå°è¯•çˆ¬å–å®Œæ•´é¡µé¢
            if len(content) < 200:
                try:
                    response = requests.get(url, timeout=15)
                    soup = BeautifulSoup(response.text, 'html.parser')
                    content = soup.get_text()[:3000]  # é™åˆ¶é•¿åº¦
                except:
                    pass
            
            # ç¬¬ä¸€é˜¶æ®µï¼šä½¿ç”¨GLM-4-PLUSç­›é€‰å…³é”®æ•°æ®æ®µè½
            filter_system_prompt = f"""
            ä½ æ˜¯æ•°æ®ç­›é€‰ä¸“å®¶ï¼Œæ“…é•¿ä»æ–°é—»æ–‡æœ¬ä¸­è¯†åˆ«åŒ…å«æ•°å€¼ã€ç»Ÿè®¡ä¿¡æ¯ã€æ¯”ä¾‹ã€è¶‹åŠ¿ç­‰å…³é”®æ•°æ®çš„æ®µè½ã€‚
            
            ä»»åŠ¡ï¼šä»æ–‡æœ¬ä¸­æå–ä¸"{topic}"ç›¸å…³çš„"{direction}"æ–¹é¢çš„å…³é”®æ•°æ®æ®µè½ã€‚
            
            è¦æ±‚ï¼š
            1. è¯†åˆ«åŒ…å«å…·ä½“æ•°å­—ã€ç™¾åˆ†æ¯”ã€ç»Ÿè®¡æ•°æ®çš„æ®µè½
            2. ä¿ç•™åŒ…å«æ—¶é—´ã€åœ°åŒºã€åˆ†ç±»ç­‰ç»´åº¦ä¿¡æ¯çš„æ®µè½
            3. è¿‡æ»¤æ‰çº¯æè¿°æ€§ã€æ— æ•°æ®ä»·å€¼çš„å†…å®¹
            4. ä¿æŒåŸæ–‡è¡¨è¿°ï¼Œä¸è¦ä¿®æ”¹æ•°æ®
            
            è¾“å‡ºæ ¼å¼ï¼šç›´æ¥è¾“å‡ºç­›é€‰åçš„å…³é”®æ®µè½ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰ä»·å€¼çš„æ•°æ®æ®µè½ï¼Œè¾“å‡º"NO_KEY_DATA"ã€‚
            """
            
            filter_messages = [
                {"role": "system", "content": filter_system_prompt},
                {"role": "user", "content": f"æ ‡é¢˜ï¼š{title}\nå†…å®¹ï¼š{content[:2500]}"}
            ]
            
            filter_response = self.client.chat_completions_create(filter_messages, temperature=0.2)
            
            if 'choices' not in filter_response or len(filter_response['choices']) == 0:
                return None
                
            key_data_segments = filter_response['choices'][0]['message']['content'].strip()
            
            if key_data_segments == "NO_KEY_DATA" or "NO_KEY_DATA" in key_data_segments:
                return None
            
            # ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨GLM-Z1-AIRXè¿›è¡Œæ·±åº¦æ¨ç†å’Œç»“æ„åŒ–
            reasoning_system_prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†ææ¨ç†ä¸“å®¶ã€‚è¯·æ·±åº¦åˆ†æä»¥ä¸‹å…³é”®æ•°æ®æ®µè½ï¼Œè¿ç”¨é€»è¾‘æ¨ç†å°†æ–‡æœ¬ä¿¡æ¯è½¬æ¢ä¸ºç»“æ„åŒ–çš„è¡¨æ ¼æ•°æ®ã€‚
            
            æ¨ç†ä»»åŠ¡ï¼š
            1. åˆ†ææ•°æ®çš„å†…åœ¨é€»è¾‘å’Œå…³è”å…³ç³»
            2. è¯†åˆ«æ•°æ®çš„å±‚æ¬¡ç»“æ„å’Œåˆ†ç±»ä½“ç³»
            3. æ¨æ–­éšå«çš„æ•°æ®å…³ç³»å’Œè®¡ç®—é€»è¾‘
            4. è®¾è®¡æœ€ä¼˜çš„è¡¨æ ¼ç»“æ„ï¼ˆåˆ—åã€æ•°æ®ç±»å‹ï¼‰
            5. ç¡®ä¿æ•°æ®çš„å®Œæ•´æ€§ã€ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§
            
            ä¸»é¢˜ï¼š{topic}
            æ•°æ®æ–¹å‘ï¼š{direction}
            
            è¾“å‡ºè¦æ±‚ï¼š
            - è®¾è®¡åˆç†çš„è¡¨æ ¼ç»“æ„ï¼Œåˆ—åä½¿ç”¨ä¸­æ–‡
            - æ¯è¡Œä»£è¡¨ä¸€ä¸ªå®Œæ•´çš„æ•°æ®è®°å½•
            - ç›´æ¥è¾“å‡ºCSVæ ¼å¼ï¼Œç¬¬ä¸€è¡Œä¸ºåˆ—å
            - å¦‚æœç»è¿‡æ¨ç†ä»æ— æ³•æ„å»ºæœ‰æ•ˆè¡¨æ ¼ï¼Œè¾“å‡º"REASONING_FAILED"
            """
            
            reasoning_messages = [
                {"role": "system", "content": reasoning_system_prompt},
                {"role": "user", "content": f"å…³é”®æ•°æ®æ®µè½ï¼š\n{key_data_segments}\n\nè¯·è¿ç”¨æ¨ç†åˆ†æï¼Œè®¾è®¡è¡¨æ ¼ç»“æ„å¹¶æå–æ•°æ®ã€‚"}
            ]
            
            # ä½¿ç”¨æ¨ç†æ¨¡å‹è¿›è¡Œæ·±åº¦åˆ†æ
            try:
                reasoning_response = self.client.chat_completions_create(
                    reasoning_messages, 
                    model="glm-z1-airx",  # ä½¿ç”¨æ¨ç†æ¨¡å‹
                    temperature=0.1
                )
            except Exception as e:
                # å¦‚æœæ¨ç†æ¨¡å‹ä¸å¯ç”¨ï¼Œå›é€€åˆ°GLM-4-PLUS
                logger.warning(f"GLM-Z1-AIRXä¸å¯ç”¨ï¼Œå›é€€åˆ°GLM-4-PLUS: {str(e)}")
                reasoning_response = self.client.chat_completions_create(
                    reasoning_messages, 
                    model="glm-4-plus",
                    temperature=0.1
                )
            
            if 'choices' in reasoning_response and len(reasoning_response['choices']) > 0:
                csv_content = reasoning_response['choices'][0]['message']['content'].strip()
                
                if csv_content == "REASONING_FAILED" or "REASONING_FAILED" in csv_content:
                    return None
                
                try:
                    # æ¸…ç†CSVå†…å®¹
                    csv_content = csv_content.replace('```csv', '').replace('```', '').strip()
                    df = pd.read_csv(StringIO(csv_content))
                    
                    # éªŒè¯æ•°æ®æ¡†
                    if len(df) > 0 and len(df.columns) > 1:
                        # æ·»åŠ å…ƒæ•°æ®åˆ—
                        df['æ•°æ®æ¥æº'] = title
                        df['æ¥æºURL'] = url
                        df['æ”¶é›†æ—¶é—´'] = pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')
                        return df
                    
                except Exception as e:
                    logger.error(f"CSV parsing error: {str(e)}")
                    return None
            
            return None
            
        except Exception as e:
            logger.error(f"Intelligent structurization error: {str(e)}")
            return None

def smart_merge_dataframes(dataframes: List[pd.DataFrame]) -> pd.DataFrame:
    """æ™ºèƒ½åˆå¹¶ä¸åŒç»“æ„çš„æ•°æ®æ¡†"""
    if not dataframes:
        return pd.DataFrame()
    
    if len(dataframes) == 1:
        return dataframes[0]
    
    try:
        # å°è¯•ç›´æ¥åˆå¹¶ï¼ˆå¦‚æœåˆ—ç»“æ„ç›¸ä¼¼ï¼‰
        return pd.concat(dataframes, ignore_index=True, sort=False)
    except Exception:
        # å¦‚æœç›´æ¥åˆå¹¶å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½åˆå¹¶ç­–ç•¥
        merged_data = []
        
        for df in dataframes:
            # å°†æ¯ä¸ªæ•°æ®æ¡†è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            for _, row in df.iterrows():
                record = {
                    'æ•°æ®é¡¹': '',
                    'æ•°å€¼': '',
                    'å•ä½': '',
                    'æ—¶é—´': '',
                    'åˆ†ç±»': '',
                    'æ•°æ®æ¥æº': row.get('æ•°æ®æ¥æº', ''),
                    'æ¥æºURL': row.get('æ¥æºURL', ''),
                    'data_direction': row.get('data_direction', ''),
                    'æ”¶é›†æ—¶é—´': row.get('æ”¶é›†æ—¶é—´', '')
                }
                
                # å°è¯•ä»è¡Œæ•°æ®ä¸­æå–æ ‡å‡†å­—æ®µ
                for col, val in row.items():
                    if col not in ['æ•°æ®æ¥æº', 'æ¥æºURL', 'data_direction', 'æ”¶é›†æ—¶é—´']:
                        if pd.api.types.is_numeric_dtype(type(val)):
                            record['æ•°å€¼'] = val
                            record['æ•°æ®é¡¹'] = col
                        else:
                            if not record['æ•°æ®é¡¹']:
                                record['æ•°æ®é¡¹'] = col
                            if 'å¹´' in str(val) or 'æœˆ' in str(val) or 'æ—¥' in str(val):
                                record['æ—¶é—´'] = val
                            else:
                                record['åˆ†ç±»'] = val
                
                merged_data.append(record)
        
        return pd.DataFrame(merged_data)

# é€‰é¢˜ç¡®å®šé˜¶æ®µ
def topic_selection_phase():
    st.header("ç¬¬ä¸€æ­¥ï¼šæ•°æ®æ–°é—»é€‰é¢˜ç¡®å®š")
    
    # åˆå§‹åŒ–session stateå˜é‡
    if 'topic_conversation' not in st.session_state:
        st.session_state.topic_conversation = []
    
    if 'suggested_topics' not in st.session_state:
        st.session_state.suggested_topics = []
    
    if 'selected_topic' not in st.session_state:
        st.session_state.selected_topic = None
    
    if 'skip_topic_selection' not in st.session_state:
        st.session_state.skip_topic_selection = False
        
    # å¦‚æœå·²ç»é€‰æ‹©äº†é€‰é¢˜ï¼Œæ˜¾ç¤ºå®ƒå¹¶è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
    if st.session_state.selected_topic:
        st.success(f"å·²é€‰æ‹©çš„é€‰é¢˜ï¼š{st.session_state.selected_topic}")
        return True
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.topic_conversation:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ç”¨æˆ·è¾“å…¥é€‰é¢˜æ–¹å‘
    topic_description = st.chat_input(
        "è¯·æè¿°ä½ æ„Ÿå…´è¶£çš„æ•°æ®æ–°é—»é€‰é¢˜æ–¹å‘...",
        key="topic_input"
    )
    
    # å½“ç”¨æˆ·æäº¤é€‰é¢˜æè¿°
    if topic_description:
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©å†å²
        st.session_state.topic_conversation.append({"role": "user", "content": topic_description})
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(topic_description)
        
        # å…ˆå°è¯•è·å–ç›¸å…³æœç´¢ç»“æœ
        search_results = search_with_tavily(topic_description)
        search_context = ""
        
        if search_results:
            search_context = "åŸºäºä»¥ä¸‹æœ€æ–°èµ„è®¯:\n" + "\n\n".join([
                f"æ ‡é¢˜: {result['title']}\nå†…å®¹: {result['content']}\næ¥æº: {result['url']}"
                for result in search_results
            ])
        
        # æ„å»ºæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šæœ‰è¶£çš„æ•°æ®æ–°é—»ç¼–è¾‘ï¼Œæ“…é•¿å¸®åŠ©è®°è€…ç¡®å®šæœ‰ä»·å€¼çš„æ•°æ®æ–°é—»é€‰é¢˜ã€‚
        è¯·æ ¹æ®ç”¨æˆ·çš„é€‰é¢˜æ–¹å‘ï¼Œç”Ÿæˆä¸‰ä¸ªæ˜ç¡®å…·ä½“çš„æ•°æ®æ–°é—»é€‰é¢˜å»ºè®®ã€‚æ¯ä¸ªé€‰é¢˜å¿…é¡»:
        1. å…·æœ‰æ–°é—»ä»·å€¼å’Œæ•°æ®é©±åŠ¨ç‰¹æ€§
        2. æ˜ç¡®å®šä¹‰äº†ç ”ç©¶é—®é¢˜å’Œå¯èƒ½çš„æ•°æ®æ¥æº
        3. æœ‰æ½œåœ¨çš„ç¤¾ä¼šå½±å“æˆ–å…¬ä¼—å…³æ³¨åº¦
        
        æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºä¸‰ä¸ªé€‰é¢˜ï¼š
        [é€‰é¢˜1]
        æ ‡é¢˜ï¼š(é€‰é¢˜æ ‡é¢˜)
        æ ¸å¿ƒé—®é¢˜ï¼š(é€‰é¢˜è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜)
        æ•°æ®æ–°é—»ä»·å€¼ï¼š(ä¸ºä»€ä¹ˆè¿™ä¸ªé€‰é¢˜å€¼å¾—åšæ•°æ®æ–°é—»)
        
        [é€‰é¢˜2]
        ...
        
        [é€‰é¢˜3]
        ...
        """
        
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # æ·»åŠ æœç´¢ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæœ‰ï¼‰
        if search_context:
            messages.append({"role": "system", "content": search_context})
        
        messages.append({"role": "user", "content": f"æˆ‘æƒ³åšä¸€ä¸ªå…³äºä»¥ä¸‹ä¸»é¢˜çš„æ•°æ®æ–°é—»ï¼š{topic_description}"})
        
        # æ˜¾ç¤ºåŠ©æ‰‹æ­£åœ¨è¾“å…¥çš„æ¶ˆæ¯
        with st.chat_message("assistant"):
            suggestion_text_container = st.empty()
            suggestion_text = ""
            
            # ä½¿ç”¨æ™ºè°±APIçš„æµå¼è¾“å‡º
            for token in client.chat_completions_create(messages, stream=True):
                suggestion_text += token
                suggestion_text_container.markdown(suggestion_text)
            
            # ä¿å­˜å®Œæ•´å›å¤åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.topic_conversation.append({"role": "assistant", "content": suggestion_text})
            
            # è§£æå»ºè®®çš„é€‰é¢˜
            topics = []
            pattern = r'\[é€‰é¢˜(\d+)\](.*?)(?=\[é€‰é¢˜\d+\]|$)'
            matches = re.findall(pattern, suggestion_text, re.DOTALL)
            
            for _, topic_content in matches:
                # æå–é€‰é¢˜ä¿¡æ¯
                title_match = re.search(r'æ ‡é¢˜ï¼š(.*?)(?:\n|$)', topic_content)
                title = title_match.group(1).strip() if title_match else "æœªå‘½åé€‰é¢˜"
                topics.append(title)
            
            st.session_state.suggested_topics = topics
    
    # å¦‚æœæœ‰å»ºè®®çš„é€‰é¢˜ï¼Œæä¾›é€‰æ‹©æŒ‰é’®
    if st.session_state.suggested_topics:
        st.subheader("è¯·é€‰æ‹©ä¸€ä¸ªé€‰é¢˜ï¼Œæˆ–é‡æ–°ç”Ÿæˆ")
        
        cols = st.columns(3)
        for i, topic in enumerate(st.session_state.suggested_topics):
            with cols[i]:
                if st.button(f"é€‰æ‹©: {topic}"):
                    st.session_state.selected_topic = topic
                    st.rerun()
        
        if st.button("é‡æ–°ç”Ÿæˆé€‰é¢˜"):
            # æ¸…é™¤ä¹‹å‰çš„å»ºè®®ï¼Œä¿ç•™å¯¹è¯å†å²
            st.session_state.suggested_topics = []
            st.rerun()
    
    # å¦‚æœç”¨æˆ·è¿˜æ²¡æœ‰é€‰æ‹©é€‰é¢˜ï¼Œè¿”å›False
    return False

# æ•°æ®æ”¶é›†æ–¹å‘ç”Ÿæˆé˜¶æ®µ
def data_collection_phase():
    st.header("ç¬¬äºŒæ­¥ï¼Œæ•´ç†æ•°æ®æ”¶é›†æ€è·¯")
    
    # åˆå§‹åŒ–session stateå˜é‡
    if 'data_directions' not in st.session_state:
        st.session_state.data_directions = None
    
    if 'data_collection_completed' not in st.session_state:
        st.session_state.data_collection_completed = False
        
    if 'data_conversation' not in st.session_state:
        st.session_state.data_conversation = []
    
    # å¦‚æœå·²ç»å®Œæˆæ•°æ®æ”¶é›†æ–¹å‘ç”Ÿæˆï¼Œæ˜¾ç¤ºç»“æœå¹¶éšè—è¾“å…¥æ¡†
    if st.session_state.data_collection_completed:
        for message in st.session_state.data_conversation:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        st.subheader("é€‰æ‹©è¦è‡ªåŠ¨æ”¶é›†çš„æ•°æ®æ–¹å‘")

        parsed = parse_data_directions(st.session_state.data_directions)
        second_hand = parsed.get("äºŒæ‰‹æ•°æ®", [])
        research = parsed.get("è°ƒç ”æ•°æ®", []) + parsed.get("è‡ªä¸»æ•°æ®æŒ–æ˜", [])

        topic = st.session_state.selected_topic

        col1, col2 = st.columns(2)
        with col1:
            st.markdown("#### äºŒæ‰‹æ•°æ®æ£€ç´¢")
            queries = [f"{topic} {d.strip()}" for d in second_hand]
            directions_input = st.text_area(
                "å¯ç¼–è¾‘çš„æ£€ç´¢é—®é¢˜ï¼ˆä¸€è¡Œä¸€ä¸ªï¼‰",
                value="\n".join(queries),
                key="second_hand_input",
                help="è¿™äº›æ£€ç´¢é—®é¢˜å°†ç”¨äºç½‘ç»œæœç´¢"
            )
            if st.button("ğŸš€ å¯åŠ¨æ™ºèƒ½æ•°æ®æ”¶é›†"):
                q_list = [d.strip() for d in directions_input.splitlines() if d.strip()]
                if q_list:
                    df = collect_data_from_directions(q_list)
                    if not df.empty:
                        processor = DataProcessor(df)
                        st.session_state['current_processor'] = processor
                        st.session_state['data_uploaded'] = True
                        st.success("âœ… æ™ºèƒ½æ•°æ®æ”¶é›†å®Œæˆå¹¶è½½å…¥æˆåŠŸï¼")
                    else:
                        st.warning("âš ï¸ æœªèƒ½è·å–åˆ°è¶³å¤Ÿçš„ç»“æ„åŒ–æ•°æ®ï¼Œè¯·å°è¯•è°ƒæ•´æ•°æ®æ”¶é›†æ–¹å‘æˆ–æ‰‹åŠ¨ä¸Šä¼ æ•°æ®")

        with col2:
            if research:
                st.markdown("#### è°ƒç ”/è‡ªä¸»æ•°æ®æŒ–æ˜")
                for d in research:
                    st.write(f"- {d}")
                if st.button("ç”Ÿæˆé—®å·", key="gen_q"):
                    st.session_state.questionnaire = generate_questionnaire(research)
                if st.button("ç”Ÿæˆçˆ¬è™«ä»£ç ", key="gen_crawler"):
                    st.session_state.crawler_code = generate_crawler_code(research)
                if st.session_state.get('questionnaire'):
                    st.subheader("é—®å·ç¤ºä¾‹")
                    st.markdown(st.session_state.questionnaire)
                if st.session_state.get('crawler_code'):
                    st.subheader("çˆ¬è™«ä»£ç ç¤ºä¾‹")
                    st.code(st.session_state.crawler_code, language='python')

        refresh_col1, refresh_col2 = st.columns([1, 10])
        with refresh_col1:
            if st.button("ğŸ”„", help="é‡æ–°ç”Ÿæˆæ•°æ®æ”¶é›†æ–¹å‘"):
                st.session_state.data_directions = None
                st.session_state.data_collection_completed = False
                st.rerun()
        with refresh_col2:
            st.write("å¦‚éœ€é‡æ–°ç”Ÿæˆæ•°æ®æ”¶é›†æ–¹å‘ï¼Œè¯·ç‚¹å‡»å·¦ä¾§åˆ·æ–°æŒ‰é’®")

        return True
    
    # å½“ç”¨æˆ·å·²ç»é€‰æ‹©äº†é€‰é¢˜ï¼Œä½†è¿˜æ²¡æœ‰ç”Ÿæˆæ•°æ®æ”¶é›†æ–¹å‘
    if st.session_state.selected_topic and not st.session_state.data_directions:
        topic = st.session_state.selected_topic
        
        # æ˜¾ç¤ºå·²æœ‰å¯¹è¯
        for message in st.session_state.data_conversation:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ç³»ç»Ÿæç¤ºï¼šå‘ŠçŸ¥ç”¨æˆ·å½“å‰é€‰é¢˜
        if len(st.session_state.data_conversation) == 0:
            with st.chat_message("assistant"):
                st.markdown(f"åŸºäºæ‚¨é€‰æ‹©çš„é€‰é¢˜: **{topic}**ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨ç”Ÿæˆè¯¦ç»†çš„æ•°æ®æ”¶é›†æ–¹å‘ã€‚")
                st.session_state.data_conversation.append({
                    "role": "assistant", 
                    "content": f"åŸºäºæ‚¨é€‰æ‹©çš„é€‰é¢˜: **{topic}**ï¼Œæˆ‘å¯ä»¥å¸®æ‚¨ç”Ÿæˆè¯¦ç»†çš„æ•°æ®æ”¶é›†æ–¹å‘ã€‚"
                })
        
        # ç”¨æˆ·è¾“å…¥æˆ–ç”ŸæˆæŒ‰é’®
        user_input = st.chat_input("è¾“å…¥ä»»ä½•é—®é¢˜æˆ–ç‚¹å‡»'ç”Ÿæˆæ•°æ®æ”¶é›†æ–¹å‘'æŒ‰é’®", key="data_input")
        generate_button = st.button("ç”Ÿæˆæ•°æ®æ”¶é›†æ–¹å‘")
        
        if generate_button or user_input:
            if user_input:
                # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å¯¹è¯
                st.session_state.data_conversation.append({"role": "user", "content": user_input})
                with st.chat_message("user"):
                    st.markdown(user_input)
                    
                # è¿›è¡Œæ™®é€šå›å¤
                with st.chat_message("assistant"):
                    response_container = st.empty()
                    response_text = ""
                    
                    # æ„å»ºæ™®é€šå¯¹è¯æç¤º
                    chat_messages = [
                        {"role": "system", "content": f"ä½ æ˜¯æ•°æ®æ–°é—»ä¸“å®¶ï¼Œæ­£åœ¨å¸®åŠ©ç”¨æˆ·è§„åˆ’é€‰é¢˜'{topic}'çš„æ•°æ®æ”¶é›†ã€‚å›ç­”ç”¨æˆ·æ‰€æœ‰å…³äºæ•°æ®æ”¶é›†çš„é—®é¢˜ã€‚"},
                    ]
                    
                    # æ·»åŠ å†å²å¯¹è¯
                    for msg in st.session_state.data_conversation:
                        chat_messages.append({"role": msg["role"], "content": msg["content"]})
                    
                    # ä½¿ç”¨æµå¼API
                    for token in client.chat_completions_create(chat_messages, stream=True):
                        response_text += token
                        response_container.markdown(response_text)
                    
                    st.session_state.data_conversation.append({"role": "assistant", "content": response_text})
            else:
                # ç”Ÿæˆæ•°æ®æ”¶é›†æ–¹å‘
                # æ„å»ºæç¤º
                system_prompt = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°æ®æ–°é—»è®°è€…ï¼Œæ“…é•¿è§„åˆ’æ•°æ®æ–°é—»æŠ¥é“çš„æ•°æ®æ”¶é›†ç­–ç•¥ã€‚

                é¦–å…ˆï¼Œè¯·åˆ¤æ–­ç”¨æˆ·é€‰æ‹©çš„é€‰é¢˜å±äºï¼š
                - ğŸ“Š æ•°æ®é©±åŠ¨å‹ï¼šä»æ•°æ®é›†å‡ºå‘ï¼Œæ²¡æœ‰é¢„è®¾ç»“è®ºï¼Œé€šè¿‡æ•°æ®æ¢ç´¢å‘ç°æ•…äº‹
                - ğŸ’¡ è¯é¢˜é©±åŠ¨å‹ï¼šåŸºäºæ˜ç¡®çš„è®®é¢˜ï¼Œæ”¶é›†æ•°æ®æ¥ä½è¯æˆ–åˆ†æç‰¹å®šç°è±¡

                ç„¶åï¼Œæ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ•°æ®æ–°é—»é€‰é¢˜ï¼Œç”Ÿæˆ6-8ä¸ªå…·ä½“çš„æ•°æ®æ£€ç´¢æ–¹å‘è®¾é—®ï¼ŒæŒ‰ç…§åˆç†çš„æ–°é—»æ•…äº‹é€’è¿›é¡ºåºæ’åˆ—ï¼š

                å¯¹æ¯ä¸ªæ•°æ®æ”¶é›†æ–¹å‘ï¼Œè¯·æ³¨æ˜ï¼š
                - ç±»å‹ï¼š1. ğŸŒ äºŒæ‰‹æ•°æ®ï¼šæä¾›å¯èƒ½å­˜åœ¨ç›¸å…³æ•°æ®çš„æŠ¥å‘Šã€å…·ä½“ç½‘ç«™ã€æ•°æ®åº“æˆ–å¼€æ”¾æ•°æ®å¹³å°ï¼Œé™„ä¸Šæ•°æ®è·å–æ–¹æ³•ã€‚2. ğŸ” è°ƒç ”æ•°æ®ï¼šæ˜ç¡®æ˜¯éœ€è¦çº¿ä¸‹èµ°è®¿ã€ç½‘ç»œå†…å®¹åˆ†æè¿˜æ˜¯é—®å·å‘æ”¾ï¼Œå¹¶æä¾›è°ƒç ”çš„é‡ç‚¹é—®é¢˜å’Œæ–¹æ³•ã€‚3. ğŸ¤– è‡ªä¸»æ•°æ®æŒ–æ˜ï¼šæ¨èé€‚åˆçˆ¬è™«æ”¶é›†çš„ç½‘ç«™ï¼Œè¯´æ˜å¯ä»¥è·å–ä»€ä¹ˆç±»å‹çš„æ•°æ®ï¼Œä»¥åŠå¤§è‡´çš„æŠ€æœ¯éš¾åº¦ã€‚
                - è¯¥æ•°æ®å°†å›ç­”ä»€ä¹ˆå…·ä½“é—®é¢˜
                - æ•°æ®è·å–çš„å¯è¡Œæ€§è¯„ä¼°ï¼ˆæ˜“/ä¸­/éš¾ï¼‰
                - è·å–æ­¤æ•°æ®å¯èƒ½é‡åˆ°çš„æŒ‘æˆ˜
                - æ•°æ®å¤„ç†å»ºè®®

                ä»¥Markdownæ ¼å¼è¾“å‡ºï¼Œæ¯ä¸ªç±»åˆ«ä½¿ç”¨ä¸‰çº§æ ‡é¢˜ï¼Œæ¯ä¸ªå…·ä½“æ–¹å‘ä½¿ç”¨å››çº§æ ‡é¢˜ï¼Œå¹¶ä½¿ç”¨è¡¨æ ¼æˆ–åˆ—è¡¨å‘ˆç°è¯¦ç»†ä¿¡æ¯ã€‚
                """
                
                messages = [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"è¯·ä¸ºæˆ‘çš„æ•°æ®æ–°é—»é€‰é¢˜ã€Š{topic}ã€‹æä¾›æ•°æ®æ”¶é›†æ–¹å‘å»ºè®®ã€‚"}
                ]
                
                # æ˜¾ç¤ºè¿›åº¦æ¡
                with st.chat_message("assistant"):
                    directions_container = st.empty()
                    directions_text = ""
                    
                    # ä½¿ç”¨æµå¼è¾“å‡º
                    for token in client.chat_completions_create(messages, stream=True):
                        directions_text += token
                        directions_container.markdown(directions_text)
                    
                    # ç¡®ä¿åœ¨æµå¼è¾“å‡ºå®Œæˆåè®¾ç½®çŠ¶æ€
                    st.session_state.data_directions = directions_text
                    st.session_state.data_collection_completed = True
                    st.session_state.data_conversation.append({
                        "role": "assistant", 
                        "content": directions_text
                    })
                
                # å¼ºåˆ¶é‡æ–°åŠ è½½é¡µé¢ä»¥åº”ç”¨æ–°çŠ¶æ€
                st.rerun()
    
    return st.session_state.data_collection_completed

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()
ZHIPU_API_KEY = '3a1df8f109f445f4b4eb898939a28a9f.0O5igS77SZZ0WGzV'  # æ›¿æ¢ä¸ºæ‚¨çš„APIå¯†é’¥
API_URL = 'https://open.bigmodel.cn/api/paas/v4/chat/completions'  # æ™ºè°±AIçš„APIåœ°å€

# ä¿®æ”¹OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–éƒ¨åˆ†
class ZhipuClient:
    def __init__(self, api_key):
        self.api_key = api_key
        self.headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        self.api_url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"  # æ™ºè°±API URL

    def chat_completions_create(self, messages, model="glm-4-plus", temperature=0.7, stream=False):
        data = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "stream": stream
        }

        try:
            if not stream:
                # éæµå¼å“åº”å¤„ç†
                response = requests.post(self.api_url, headers=self.headers, json=data)
                response.raise_for_status()
                return response.json()
            else:
                # æµå¼å“åº”å¤„ç†
                response = requests.post(self.api_url, headers=self.headers, json=data, stream=True)
                response.raise_for_status()
                
                for line in response.iter_lines():
                    if line:
                        line = line.decode('utf-8')
                        if line.startswith('data: '):
                            json_str = line[6:]  # å»æ‰'data: 'å‰ç¼€
                            if json_str.strip() == '[DONE]':
                                break
                            try:
                                json_data = json.loads(json_str)
                                if 'choices' in json_data and len(json_data['choices']) > 0:
                                    content = json_data['choices'][0].get('delta', {}).get('content', '')
                                    if content:
                                        yield content
                            except json.JSONDecodeError:
                                pass
                        
        except Exception as e:
            if stream:
                yield f"APIè°ƒç”¨å¤±è´¥: {str(e)}"
            else:
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")

# æ›¿æ¢OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–
client = ZhipuClient(api_key=ZHIPU_API_KEY)

def get_data_summary(df: pd.DataFrame) -> str:
    """ç”Ÿæˆæ•°æ®é›†çš„ç®€è¦æè¿°"""
    summary = []

    # åŸºæœ¬ä¿¡æ¯
    summary.append(f"æ•°æ®é›†åŒ…å« {len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—")

    # åˆ—ä¿¡æ¯
    for col in df.columns:
        col_type = df[col].dtype
        unique_count = df[col].nunique()
        null_count = df[col].isnull().sum()

        # å¯¹äºæ•°å€¼åˆ—ï¼Œæ·»åŠ åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        if pd.api.types.is_numeric_dtype(df[col]):
            stats = df[col].describe()
            col_info = (f"åˆ— '{col}' (ç±»å‹: {col_type}): "
                       f"å–å€¼èŒƒå›´ {stats['min']:.2f} åˆ° {stats['max']:.2f}, "
                       f"å¹³å‡å€¼ {stats['mean']:.2f}, "
                       f"ä¸åŒå€¼æ•°é‡ {unique_count}")
        else:
            # å¯¹äºéæ•°å€¼åˆ—ï¼Œæ˜¾ç¤ºå”¯ä¸€å€¼æ•°é‡å’Œç¤ºä¾‹å€¼
            sample_values = df[col].dropna().sample(min(3, unique_count)).tolist()
            col_info = (f"åˆ— '{col}' (ç±»å‹: {col_type}): "
                       f"ä¸åŒå€¼æ•°é‡ {unique_count}, "
                       f"ç¤ºä¾‹å€¼: {', '.join(map(str, sample_values))}")

        if null_count > 0:
            col_info += f", å­˜åœ¨ {null_count} ä¸ªç©ºå€¼"

        summary.append(col_info)

    return "\n".join(summary)

def format_visualization_suggestions(response_text: str) -> str:
    """å°†APIå“åº”æ ¼å¼åŒ–ä¸ºHTMLæ ·å¼çš„è¾“å‡º"""

    # å®šä¹‰CSSæ ·å¼
    css = """
        <style>
            .suggestion {
                background-color: #f8f9fa;
                padding: 15px 20px;
                margin-bottom: 20px;
                border-left: 4px solid #4A90E2;
                border-radius: 4px;
            }
            .suggestion-number {
                font-size: 18px;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 15px;
            }
            .label {
                color: #4A90E2;
                font-weight: bold;
                margin-top: 10px;
            }
            .content {
                color: #333;
                margin-bottom: 10px;
                line-height: 1.5;
            }
        </style>
    """

    # å°†æ–‡æœ¬åˆ†å‰²æˆä¸åŒçš„å»ºè®®
    suggestions = response_text.split("\n\n---\n\n")

    html_parts = [css]

    for i, suggestion in enumerate(suggestions, 1):
        # å¼€å§‹æ–°çš„å»ºè®®åŒºå—
        html_parts.append(f'<div class="suggestion">')

        # è§£ææ¯ä¸ªéƒ¨åˆ†
        sections = suggestion.strip().split("\n\n")

        # å…ˆæ·»åŠ å»ºè®®ç¼–å·
        html_parts.append(f'<div class="suggestion-number">å»ºè®® {i}</div>')

        # å¤„ç†æ¯ä¸ªéƒ¨åˆ†
        for section in sections:
            if "[" in section and "]" in section:
                header = section[section.find("[")+1:section.find("]")]
                content = section[section.find("]")+1:].strip()
                html_parts.append(f'<div class="label">{header}</div>')
                html_parts.append(f'<div class="content">{content}</div>')

        html_parts.append('</div>')

    return "".join(html_parts)

# ä¿®æ”¹get_llm_responseå‡½æ•°ä¸­çš„promptéƒ¨åˆ†
def get_llm_response(prompt: str, df: Optional[pd.DataFrame] = None) -> str:
    """è·å–LLMçš„å¯è§†åŒ–å»ºè®®ï¼Œä½¿ç”¨æµå¼è¾“å‡º"""
    try:
        # å¦‚æœæä¾›äº†DataFrameï¼Œç”Ÿæˆæ•°æ®æ¦‚è¦
        if df is not None:
            data_summary = get_data_summary(df)
            full_prompt = f"""è¯·ä½œä¸ºæ•°æ®å¯è§†åŒ–ä¸“å®¶åˆ†æä»¥ä¸‹æ•°æ®é›†ï¼š

æ•°æ®é›†æ¦‚è¦ï¼š
{data_summary}

ç”¨æˆ·é—®é¢˜ï¼š
{prompt}"""
        else:
            full_prompt = prompt

        # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯æ•°ç»„
        messages = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä¸ªä¸­å›½æ•°æ®æ–°é—»ä¸“å®¶ã€‚è¯·åˆ†ææ•°æ®å¹¶æä¾›3-4ä¸ªå…·ä½“çš„æ•°æ®å¯è§†åŒ–å»ºè®®ã€‚

æ¯ä¸ªå»ºè®®å¿…é¡»æŒ‰ç…§ä»¥ä¸‹å›ºå®šæ ¼å¼è¾“å‡ºï¼Œç¡®ä¿æ¯ä¸ªéƒ¨åˆ†éƒ½å¦èµ·æ–°è¡Œï¼š

[æ ‡é¢˜]
(å¸¦æœ‰æ¢ç´¢æ€§ä¸æ–°é—»ä»·å€¼çš„æ ‡é¢˜)

[ä½¿ç”¨åˆ—]
(æ˜ç¡®æŒ‡å‡ºä½¿ç”¨å“ªäº›åˆ—)

[å›¾è¡¨ç±»å‹]
(æ¨èä½¿ç”¨çš„å›¾è¡¨ç±»å‹ï¼Œå¦‚æŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€æ•£ç‚¹å›¾ç­‰)

[ç¼˜ç”±]
(è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªå¯è§†åŒ–æ–¹æ¡ˆæœ‰ä»·å€¼)

---

å»ºè®® 2ï¼š
(æŒ‰ç›¸åŒæ ¼å¼ç»§ç»­...)"""
            },
            {"role": "user", "content": full_prompt}
        ]

        # ä½¿ç”¨æµå¼è¾“å‡º
        visualization_text = ""
        for token in client.chat_completions_create(messages, model="glm-4-plus", stream=True):
            visualization_text += token
        
        # æ ¼å¼åŒ–å¯è§†åŒ–å»ºè®®
        return format_visualization_suggestions(visualization_text)
    except Exception as e:
        logger.error(f"LLM API é”™è¯¯: {str(e)}")
        return None

# ä¿®æ”¹cached_api_callå‡½æ•°
@functools.lru_cache(maxsize=32)
def cached_api_call(prompt: str) -> str:
    """ç¼“å­˜APIè°ƒç”¨ç»“æœ"""
    try:
        response = get_llm_response(prompt)
        if response is not None:
            return response
        else:
            st.error("æ— æ³•è·å–AIå»ºè®®ï¼Œè¯·ç¨åé‡è¯•")
            return "æ— æ³•è·å–AIå»ºè®®ï¼Œè¯·ç¨åé‡è¯•"
    except Exception as e:
        st.error(f"APIè°ƒç”¨é”™è¯¯: {str(e)}")
        logger.error(f"APIè°ƒç”¨é”™è¯¯: {str(e)}")
        return "APIè°ƒç”¨å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®æˆ–ç½‘ç»œè¿æ¥"

# Data processing class
class DataProcessor:
    def __init__(self, file_or_df):
        self.df = None
        if isinstance(file_or_df, pd.DataFrame):
            # ç›´æ¥ä½¿ç”¨DataFrameï¼Œä¸æ–‡ä»¶ä¸Šä¼ ä¿æŒä¸€è‡´çš„å¤„ç†æ–¹å¼
            self.df = file_or_df
            self.clean_data()  # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æ¸…ç†æ–¹æ³•
        else:
            self.file_type = file_or_df.name.split('.')[-1].lower()
            self.process_file(file_or_df)

    def clean_data(self):
        """ç»Ÿä¸€çš„æ•°æ®æ¸…ç†æ–¹æ³•"""
        if self.df is not None:
            # æ¸…ç†åˆ—å
            self.df.columns = self.df.columns.astype(str)
            self.df.columns = [col.strip() for col in self.df.columns]

            # å¯¹æ¯åˆ—è¿›è¡ŒåŸºç¡€å¤„ç†
            for col in self.df.columns:
                # å¤„ç†æ—¥æœŸæ—¶é—´åˆ—
                if any(keyword in col.lower() for keyword in ['time', 'date']):
                    try:
                        self.df[col] = pd.to_datetime(self.df[col])
                    except:
                        continue

                # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹ï¼ˆå¦‚æœé€‚åˆçš„è¯ï¼‰
                elif self.df[col].dtype == 'object':
                    try:
                        numeric_values = pd.to_numeric(self.df[col], errors='coerce')
                        if numeric_values.notna().sum() / len(numeric_values) > 0.5:
                            self.df[col] = numeric_values
                    except:
                        continue

    def process_file(self, file):
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        try:
            # è¯»å–æ–‡ä»¶
            if self.file_type == 'csv':
                self.df = pd.read_csv(file, encoding='utf-8')
            elif self.file_type == 'xlsx':
                self.df = pd.read_excel(file, engine='openpyxl')
            elif self.file_type == 'xls':
                self.df = pd.read_excel(file, engine='xlrd')
            elif self.file_type == 'json':
                self.df = pd.read_json(file)
            else:
                st.error("ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚è¯·ä¸Šä¼  CSVã€XLSXã€XLS æˆ– JSON æ–‡ä»¶ã€‚")
                return

            self.clean_data()  # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æ¸…ç†æ–¹æ³•

        except UnicodeDecodeError:
            try:
                if self.file_type == 'csv':
                    self.df = pd.read_csv(file, encoding='gbk')
                    self.clean_data()
            except Exception as e:
                st.error(f"æ–‡ä»¶ç¼–ç é”™è¯¯: {str(e)}")
                logger.error(f"æ–‡ä»¶ç¼–ç é”™è¯¯: {str(e)}")
                raise
        except Exception as e:
            st.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")
            logger.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")
            raise

    def get_data_profile(self) -> Dict:
        """Generate basic data profile"""
        if self.df is None:  # Handle case where file processing failed
            return {}

        profile = {
            'columns': list(self.df.columns),
            'dtypes': {str(k): str(v) for k, v in self.df.dtypes.to_dict().items()},
            'null_counts': self.df.isnull().sum().to_dict(),
        }

        numeric_cols = self.df.select_dtypes(include=['int64', 'float64']).columns
        if not numeric_cols.empty:
            profile['statistics'] = {
                col: {
                    str(k): float(v) if pd.notnull(v) else None
                    for k, v in self.df[col].describe().to_dict().items()
                }
                for col in numeric_cols
            }

        return profile

# Visualization Generator (improved)
class VisualizationGenerator:
    def __init__(self, df: pd.DataFrame):
        self.df = df
        self.color_schemes = {
            'nyt': ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'],
            'modern': ['#4A90E2', '#50E3C2', '#F5A623', '#D0021B', '#9013FE', '#417505', '#7ED321', '#BD10E0', '#8B572A', '#4A4A4A'],
            'soft': ['#ADD8E6', '#FF9999', '#FFB6C1', '#98D8C8', '#B0E0E6', '#FFDAB9', '#DDA0DD', '#E6E6FA', '#F0E68C', '#E0FFFF']
        }
        self.current_theme = 'modern'  # é»˜è®¤ä¸»é¢˜
        self.theme_map = {
            'modern': ThemeType.LIGHT,
            'nyt': ThemeType.DARK,
            'soft': ThemeType.ESSOS
        }

    def set_theme(self, theme_name: str):
        """è®¾ç½®å½“å‰ä¸»é¢˜"""
        if theme_name in self.color_schemes:
            self.current_theme = theme_name

    def analyze_column(self, column: str) -> dict:
        series = self.df[column]
        unique_count = series.nunique()
        total_count = len(series)
        is_numeric = pd.api.types.is_numeric_dtype(series)

        return {
            'unique_count': unique_count,
            'total_count': total_count,
            'is_numeric': is_numeric,
            'dtype': str(series.dtype)
        }

    def preprocess_categorical_data(self, column: str) -> pd.DataFrame:
        """å¤„ç†åˆ†ç±»æ•°æ®"""
        # ç›´æ¥ä½¿ç”¨value_counts()è·å–åˆ†ç±»ç»Ÿè®¡
        value_counts = self.df[column].value_counts()
        
        # å¦‚æœç±»åˆ«è¿‡å¤šï¼Œåªä¿ç•™å‰10ä¸ª
        if len(value_counts) > 10:
            value_counts = value_counts.head(10)
        
        return pd.DataFrame({
            'category': value_counts.index,
            'count': value_counts.values
        })

    def suggest_chart_type(self, columns: List[str]) -> str:
        """æ ¹æ®æ•°æ®ç‰¹å¾è‡ªåŠ¨æ¨èå›¾è¡¨ç±»å‹"""
        if len(columns) == 1:
            column = columns[0]
            analysis = self.analyze_column(column)
            
            if not analysis['is_numeric']:
                if analysis['unique_count'] <= 10:  # å°‘é‡åˆ†ç±»
                    return 'pie' if analysis['unique_count'] <= 6 else 'bar'
                else:  # å¤§é‡åˆ†ç±»
                    return 'bar'
            else:  # æ•°å€¼æ•°æ®
                if analysis['unique_count'] > 10:  # è¿ç»­æ•°å€¼
                    return 'histogram'
                else:  # ç¦»æ•£æ•°å€¼
                    return 'bar'
        else:  # åŒå˜é‡åˆ†æ
            x_col, y_col = columns[:2]
            x_analysis = self.analyze_column(x_col)
            y_analysis = self.analyze_column(y_col)
            
            if x_analysis['is_numeric'] and y_analysis['is_numeric']:
                return 'scatter'
            elif (not x_analysis['is_numeric']) and y_analysis['is_numeric']:
                return 'box' if x_analysis['unique_count'] <= 10 else 'violin'
            elif x_analysis['is_numeric'] and (not y_analysis['is_numeric']):
                return 'bar'
            else:
                return 'heatmap' if (x_analysis['unique_count'] <= 20 and y_analysis['unique_count'] <= 20) else 'bar'

    def generate_chart(self, columns: list, chart_type: str = 'auto', title: str = None, source: str = None, show_legend: bool = True):
        """ä½¿ç”¨pyechartsç”Ÿæˆå›¾è¡¨"""
        try:
            # å¦‚æœæ˜¯è‡ªåŠ¨æ¨¡å¼ï¼Œæ¨èå›¾è¡¨ç±»å‹
            if chart_type == 'auto':
             chart_type = self.suggest_chart_type(columns)

            # è®¾ç½®é»˜è®¤å®½é«˜
            width = "100%"
            height = "500px"
        
            # å›¾è¡¨æ ‡é¢˜
            title_text = title or (f'{columns[0]} åˆ†å¸ƒ' if len(columns) == 1 else f'{columns[1]} vs {columns[0]}')
        
            # é€‰æ‹©å½“å‰ä¸»é¢˜çš„é¢œè‰²æ–¹æ¡ˆ
            colors = self.color_schemes[self.current_theme]
            theme = self.theme_map[self.current_theme]
        
            # è®¾ç½®å›¾ä¾‹é€‰é¡¹
            legend_opts = opts.LegendOpts(is_show=show_legend, pos_bottom="10%", orient="horizontal", pos_left="center")
            
            if len(columns) == 1:
                column = columns[0]
                analysis = self.analyze_column(column)
                
                # æ£€æŸ¥æ•°æ®ç±»å‹ä¸å›¾è¡¨ç±»å‹çš„åŒ¹é…æ€§
                if not analysis['is_numeric'] and chart_type in ['histogram', 'box', 'violin', 'heatmap']:
                    st.warning("æç¤ºï¼šæ–‡æœ¬/åˆ†ç±»æ•°æ®ä¸é€‚åˆä½¿ç”¨æ•°å€¼å‹å›¾è¡¨ï¼ˆç›´æ–¹å›¾ã€ç®±çº¿å›¾ã€å°æç´å›¾ã€çƒ­åŠ›å›¾ï¼‰è¿›è¡Œå±•ç¤ºã€‚è¯·é€‰æ‹©é¥¼å›¾ã€æŸ±çŠ¶å›¾ç­‰åˆ†ç±»å›¾è¡¨ã€‚")
                    return None
                
                if not analysis['is_numeric']:
                    processed_data = self.preprocess_categorical_data(column)
                    
                    if chart_type == 'pie':
                        # åˆ›å»ºé¥¼å›¾
                        chart = (
                            Pie(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                            .add(
                                series_name=column,
                                data_pair=[list(z) for z in zip(processed_data['category'], processed_data['count'])],
                                radius=["40%", "70%"],
                            )
                            .set_global_opts(
                                title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                                legend_opts=opts.LegendOpts(pos_bottom="10%", orient="horizontal", pos_left="center"),
                            )
                            .set_series_opts(label_opts=opts.LabelOpts(formatter="{b}: {c} ({d}%)"))
                        )
                        
                    elif chart_type == 'bar':
                        # åˆ›å»ºæŸ±çŠ¶å›¾
                        chart = (
                            Bar(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                            .add_xaxis(processed_data['category'].tolist())
                            .add_yaxis(column, processed_data['count'].tolist())
                            .set_global_opts(
                                title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                                xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=0)),
                                legend_opts=opts.LegendOpts(is_show=False),
                            )
                        )
                        
                    elif chart_type == 'treemap':
                        # åˆ›å»ºæ ‘å›¾
                        data = [{"name": str(c), "value": int(v)} for c, v in zip(processed_data['category'], processed_data['count'])]
                        chart = (
                            TreeMap(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                            .add(
                                series_name=column,
                                data=data,
                                visual_min=0,
                                visual_max=max(processed_data['count']),
                                label_opts=opts.LabelOpts(position="inside"),
                            )
                            .set_global_opts(title_opts=opts.TitleOpts(title=title_text))
                        )
                    
                    elif chart_type == 'sunburst':
                        # åˆ›å»ºæ—­æ—¥å›¾
                        data = [{"name": str(c), "value": int(v)} for c, v in zip(processed_data['category'], processed_data['count'])]
                        chart = (
                            Sunburst(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                            .add(
                                series_name=column,
                                data_pair=data,
                                radius=[0, "90%"],
                            )
                            .set_global_opts(title_opts=opts.TitleOpts(title=title_text))
                        )
                
                elif analysis['is_numeric']:
                    if chart_type == 'histogram':
                        # å¤„ç†ç›´æ–¹å›¾ï¼Œä½¿ç”¨Barå®ç°
                        # ç”Ÿæˆç›´æ–¹å›¾æ•°æ®
                        hist, bin_edges = np.histogram(self.df[column].dropna(), bins='auto')
                        bin_labels = [f"{bin_edges[i]:.2f}-{bin_edges[i+1]:.2f}" for i in range(len(bin_edges)-1)]
                        
                        chart = (
                            Bar(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                            .add_xaxis(bin_labels)
                            .add_yaxis("é¢‘ç‡", hist.tolist())
                            .set_global_opts(
                                title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                                xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=45)),
                            )
                        )
                    
                    elif chart_type == 'box':
                        # ç®±çº¿å›¾æ•°æ®å‡†å¤‡
                        data = self.df[column].dropna().tolist()
                        chart = (
                            Boxplot(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                            .add_xaxis([column])
                            .add_yaxis("", self._prepare_boxplot_data(data))
                            .set_global_opts(
                                title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                                yaxis_opts=opts.AxisOpts(name=column),
                            )
                        )
                    
                    elif chart_type == 'violin':
                        # pyechartsä¸ç›´æ¥æ”¯æŒå°æç´å›¾ï¼Œè¿™é‡Œç”¨boxplotæ›¿ä»£
                        data = self.df[column].dropna().tolist()
                        st.warning("EChartsä¸ç›´æ¥æ”¯æŒå°æç´å›¾ï¼Œå·²æ›¿æ¢ä¸ºç®±çº¿å›¾å±•ç¤º")
                        chart = (
                            Boxplot(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                            .add_xaxis([column])
                            .add_yaxis("", self._prepare_boxplot_data(data))
                            .set_global_opts(
                                title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                                yaxis_opts=opts.AxisOpts(name=column),
                            )
                        )
                
            else:  # åŒå˜é‡åˆ†æ
                x_col, y_col = columns[:2]
                
                if chart_type == 'scatter':
                    # æ•£ç‚¹å›¾
                    chart = (
                        Scatter(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                        .add_xaxis(self.df[x_col].tolist())
                        .add_yaxis(
                            y_col,
                            self.df[[x_col, y_col]].dropna().values.tolist(),
                            symbol_size=10,
                        )
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                            xaxis_opts=opts.AxisOpts(name=x_col),
                            yaxis_opts=opts.AxisOpts(name=y_col),
                            visualmap_opts=opts.VisualMapOpts(type_="size", max_=100, min_=10),
                        )
                    )
                
                elif chart_type == 'line':
                    # æŠ˜çº¿å›¾
                    chart = (
                        Line(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                        .add_xaxis(self.df[x_col].tolist())
                        .add_yaxis(
                            y_col,
                            self.df[y_col].tolist(),
                            symbol_size=8,
                        )
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                            xaxis_opts=opts.AxisOpts(
                                name=x_col,
                                type_="category" if not pd.api.types.is_numeric_dtype(self.df[x_col]) else "value"
                            ),
                            yaxis_opts=opts.AxisOpts(name=y_col),
                            datazoom_opts=[opts.DataZoomOpts()],
                            legend_opts=opts.LegendOpts(pos_bottom="10%", orient="horizontal", pos_left="center"),
                        )
                    )
                
                elif chart_type == 'bar':
                    # æŸ±çŠ¶å›¾
                    chart = (
                        Bar(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                        .add_xaxis(self.df[x_col].astype(str).tolist())
                        .add_yaxis(y_col, self.df[y_col].tolist())
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                            xaxis_opts=opts.AxisOpts(
                                name=x_col,
                                axislabel_opts=opts.LabelOpts(rotate=45)
                            ),
                            yaxis_opts=opts.AxisOpts(name=y_col),
                            datazoom_opts=[opts.DataZoomOpts()],
                            legend_opts=opts.LegendOpts(pos_bottom="10%", orient="horizontal", pos_left="center"),
                        )
                    )
                
                elif chart_type == 'box':
                    # åˆ†ç»„ç®±çº¿å›¾ - ç®€åŒ–å®ç°
                    st.warning("EChartsä¸­çš„åˆ†ç»„ç®±çº¿å›¾å®ç°è¾ƒä¸ºå¤æ‚ï¼Œå±•ç¤ºæ•ˆæœå¯èƒ½ä¸é¢„æœŸæœ‰å·®å¼‚")
                    grouped = self.df.groupby(x_col)[y_col].apply(list).reset_index()
                    chart = (
                        Boxplot(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                        .add_xaxis(grouped[x_col].tolist())
                        .add_yaxis(
                            y_col,
                            [self._prepare_boxplot_data(data)[0] for data in grouped[y_col]]
                        )
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                            xaxis_opts=opts.AxisOpts(name=x_col),
                            yaxis_opts=opts.AxisOpts(name=y_col),
                        )
                    )
                
                elif chart_type == 'violin':
                    # ç®€åŒ–å®ç°ï¼špyechartsä¸ç›´æ¥æ”¯æŒå°æç´å›¾
                    st.warning("EChartsä¸ç›´æ¥æ”¯æŒå°æç´å›¾ï¼Œå·²æ›¿æ¢ä¸ºåˆ†ç»„ç®±çº¿å›¾å±•ç¤º")
                    grouped = self.df.groupby(x_col)[y_col].apply(list).reset_index()
                    chart = (
                        Boxplot(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                        .add_xaxis(grouped[x_col].tolist())
                        .add_yaxis(
                            y_col,
                            [self._prepare_boxplot_data(data)[0] for data in grouped[y_col]]
                        )
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                            xaxis_opts=opts.AxisOpts(name=x_col),
                            yaxis_opts=opts.AxisOpts(name=y_col),
                        )
                    )
                
                elif chart_type == 'heatmap':
                    # çƒ­åŠ›å›¾
                    # ç®€åŒ–å®ç°ï¼šåˆ›å»ºæ•°æ®é€è§†è¡¨
                    if pd.api.types.is_numeric_dtype(self.df[y_col]):
                        # å¦‚æœyæ˜¯æ•°å€¼åˆ—ï¼Œè®¡ç®—å¹³å‡å€¼
                        pivot_data = self.df.pivot_table(
                            values=y_col,
                            index=x_col,
                            aggfunc='mean'
                        ).reset_index()
                        x_data = pivot_data[x_col].astype(str).tolist()
                        y_data = [y_col]
                        heat_data = [[0, 0, val] for val in pivot_data[y_col]]
                    else:
                        # å¦‚æœyæ˜¯åˆ†ç±»åˆ—ï¼Œè®¡ç®—é¢‘æ•°
                        counts = self.df.groupby([x_col, y_col]).size().reset_index(name='count')
                        x_data = sorted(counts[x_col].unique().astype(str).tolist())
                        y_data = sorted(counts[y_col].unique().astype(str).tolist())
                        heat_data = []
                        for _, row in counts.iterrows():
                            x_idx = x_data.index(str(row[x_col]))
                            y_idx = y_data.index(str(row[y_col]))
                            heat_data.append([x_idx, y_idx, row['count']])
                    
                    chart = (
                        HeatMap(init_opts=opts.InitOpts(width=width, height=height, theme=theme))
                        .add_xaxis(x_data)
                        .add_yaxis(
                            "",
                            y_data,
                            heat_data,
                        )
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title=title_text, pos_left="center"),
                            visualmap_opts=opts.VisualMapOpts(),
                            xaxis_opts=opts.AxisOpts(name=x_col),
                            yaxis_opts=opts.AxisOpts(name=y_col),
                        )
                    )

            # æ·»åŠ æ•°æ®æ¥æºæ³¨é‡Š
            if source:
                chart.set_global_opts(
                    title_opts=opts.TitleOpts(
                        title=title_text,
                        subtitle=f"æ•°æ®æ¥æº: {source}",
                        pos_left="center",
                        title_textstyle_opts=opts.TextStyleOpts(font_size=22)  # è®¾ç½®æ›´å¤§çš„æ ‡é¢˜å­—å·
                    )
                )

            return chart

        except Exception as e:
            st.error(f"ç”Ÿæˆå›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
            logger.error(f"å›¾è¡¨ç”Ÿæˆé”™è¯¯: {str(e)}")
            return None

    # è¾…åŠ©æ–¹æ³•ï¼šä¸ºç®±çº¿å›¾å‡†å¤‡æ•°æ®
    def _prepare_boxplot_data(self, data):
        """ä¸ºEChartsç®±çº¿å›¾å‡†å¤‡æ•°æ®"""
        result = []
        if not data:
            return [[0, 0, 0, 0, 0]]
            
        data = sorted(data)
        q1, q2, q3 = np.percentile(data, [25, 50, 75])
        iqr = q3 - q1
        low_whisker = max(min(data), q1 - 1.5 * iqr)
        high_whisker = min(max(data), q3 + 1.5 * iqr)
        result.append([low_whisker, q1, q2, q3, high_whisker])
        return result

    def evaluate_chart(self, chart_type: str, columns: List[str]) -> Tuple[str, List[str], str]:
        """è¯„ä¼°å›¾è¡¨é€‚ç”¨æ€§"""
        if chart_type == 'auto':
            return "éå¸¸é€‚åˆ", ["æ•°æ®åˆ†æä»·å€¼", "å›¾è¡¨ç±»å‹é€‚ç”¨æ€§"], "è‡ªåŠ¨é€‰æ‹©çš„å›¾è¡¨ç±»å‹æœ€é€‚åˆå½“å‰æ•°æ®ç‰¹å¾ã€‚"

        data_types = [self.df[col].dtype for col in columns]
        num_numeric = sum(1 for dtype in data_types if pd.api.types.is_numeric_dtype(dtype))
        num_categorical = sum(1 for dtype in data_types if dtype == 'object' or str(dtype).startswith('datetime'))
        num_columns = len(columns)
        score = "åŸºæœ¬é€‚åˆ"  # é»˜è®¤ä¸º"åŸºæœ¬é€‚åˆ"
        feedback_dimensions = ["æ•°æ®åˆ†æä»·å€¼", "å›¾è¡¨ç±»å‹é€‚ç”¨æ€§"]
        feedback = ""

        if chart_type == 'line':
            # æ£€æŸ¥Xè½´æ˜¯å¦ä¸ºæ—¶é—´ç±»å‹
            if num_columns == 2:
                x_col = columns[0]
                is_time_col = pd.api.types.is_datetime64_any_dtype(self.df[x_col]) or \
                             any(keyword in x_col.lower() for keyword in ['time', 'date', 'æ—¶é—´', 'æ—¥æœŸ', 'å¹´', 'æœˆ'])
                if not is_time_col:
                    score = "ä¸é€‚åˆ"
                    feedback = "æŠ˜çº¿å›¾æœ€é€‚åˆå±•ç¤ºéšæ—¶é—´å˜åŒ–çš„è¶‹åŠ¿ã€‚å½“å‰Xè½´ä¸æ˜¯æ—¶é—´ç±»å‹ï¼Œå»ºè®®ä½¿ç”¨å…¶ä»–å›¾è¡¨ç±»å‹ã€‚"
                else:
                    score = "éå¸¸é€‚åˆ"
                    feedback = "æŠ˜çº¿å›¾å¾ˆå¥½åœ°å±•ç¤ºäº†æ•°æ®éšæ—¶é—´çš„å˜åŒ–è¶‹åŠ¿ã€‚"
            else:
                score = "ä¸é€‚åˆ"
                feedback = "æŠ˜çº¿å›¾éœ€è¦ä¸€ä¸ªæ—¶é—´ç±»å‹çš„Xè½´å’Œä¸€ä¸ªæ•°å€¼ç±»å‹çš„Yè½´ã€‚"
        elif chart_type == 'pie':
            if num_columns != 1 or num_categorical != 1:
                score = "ä¸é€‚åˆ"
                feedback = "é¥¼å›¾æœ€é€‚åˆå±•ç¤ºå•ä¸ªåˆ†ç±»å˜é‡çš„åˆ†å¸ƒæƒ…å†µã€‚"
            else:
                score = "éå¸¸é€‚åˆ"
                feedback = "é¥¼å›¾å®Œç¾å±•ç°äº†å•ä¸ªåˆ†ç±»å˜é‡çš„åˆ†å¸ƒæ¯”ä¾‹ã€‚"
        elif chart_type == 'bar':
            if num_columns == 1 and num_categorical == 1:
                score = "éå¸¸é€‚åˆ"
                feedback = "æŸ±çŠ¶å›¾å¾ˆå¥½åœ°å±•ç¤ºäº†åˆ†ç±»æ•°æ®çš„å¯¹æ¯”ã€‚"
            elif num_columns == 2 and num_categorical == 1 and num_numeric == 1:
                score = "éå¸¸é€‚åˆ"
                feedback = "æŸ±çŠ¶å›¾æœ‰æ•ˆåœ°å±•ç¤ºäº†ä¸åŒç±»åˆ«çš„æ•°å€¼å¯¹æ¯”ã€‚"
            else:
                score = "åŸºæœ¬é€‚åˆ"
                feedback = "æŸ±çŠ¶å›¾å¯ä»¥å±•ç¤ºå½“å‰æ•°æ®ï¼Œä½†å¯èƒ½å­˜åœ¨æ›´å¥½çš„å¯è§†åŒ–æ–¹å¼ã€‚"
        elif chart_type == 'scatter':
            if num_columns == 2 and num_numeric == 2:
                score = "éå¸¸é€‚åˆ"
                feedback = "æ•£ç‚¹å›¾å®Œç¾å±•ç¤ºäº†ä¸¤ä¸ªæ•°å€¼å˜é‡é—´çš„å…³ç³»ã€‚"
            else:
                score = "ä¸é€‚åˆ"
                feedback = "æ•£ç‚¹å›¾ä»…é€‚ç”¨äºå±•ç¤ºä¸¤ä¸ªæ•°å€¼å˜é‡çš„å…³ç³»ã€‚"
        elif chart_type == 'histogram':
            if num_columns == 1 and num_numeric == 1:
                score = "éå¸¸é€‚åˆ"
                feedback = "ç›´æ–¹å›¾å¾ˆå¥½åœ°å±•ç¤ºäº†æ•°å€¼å˜é‡çš„åˆ†å¸ƒæƒ…å†µã€‚"
            else:
                score = "ä¸é€‚åˆ"
                feedback = "ç›´æ–¹å›¾ä»…é€‚ç”¨äºå±•ç¤ºå•ä¸ªæ•°å€¼å˜é‡çš„åˆ†å¸ƒã€‚"
        else:  # å…¶ä»–å›¾è¡¨ç±»å‹
            score = "åŸºæœ¬é€‚åˆ"
            feedback = "æ­¤å›¾è¡¨ç±»å‹å¯ä»¥å±•ç¤ºå½“å‰æ•°æ®ã€‚"

        return score, feedback_dimensions, feedback

    def get_chart_data(self, columns: List[str]) -> pd.DataFrame:
        """è·å–ç”¨äºç”Ÿæˆæ•°æ®æ•…äº‹çš„å›¾è¡¨æ•°æ®"""
        if len(columns) == 1:
            column = columns[0]
            if not pd.api.types.is_numeric_dtype(self.df[column]):
                # å¯¹äºåˆ†ç±»æ•°æ®ï¼Œè®¡ç®—é¢‘ç‡å’Œç™¾åˆ†æ¯”
                value_counts = self.df[column].value_counts()
                percentages = value_counts / len(self.df) * 100
                return pd.DataFrame({
                    'category': value_counts.index,
                    'count': value_counts.values,
                    'percentage': percentages.values
                })
            else:
                # å¯¹äºæ•°å€¼æ•°æ®ï¼Œè®¡ç®—åŸºæœ¬ç»Ÿè®¡é‡
                stats = self.df[column].describe()
                return pd.DataFrame({
                    'ç»Ÿè®¡æŒ‡æ ‡': stats.index,
                    'å€¼': stats.values
                })
        else:
            # å¯¹äºåŒå˜é‡åˆ†æï¼Œè¿”å›åŸå§‹æ•°æ®çš„ç›¸å…³éƒ¨åˆ†
            return self.df[columns].copy()

def simulate_progress_bar():
    """æ¨¡æ‹Ÿè¿›åº¦æ¡åŠ¨ç”»"""
    progress_bar = st.progress(0)
    progress_text = st.empty()
    progress = 0

    while progress < 90:
        # éçº¿æ€§è¿›åº¦å¢åŠ ï¼Œå¼€å§‹å¿«ï¼Œåé¢æ…¢
        increment = max(0.3, (90 - progress) / 50)
        progress = min(90, progress + increment)

        # æ›´æ–°è¿›åº¦æ¡å’Œæ–‡æœ¬
        progress_bar.progress(int(progress))
        progress_text.text(f'åˆ†æè¿›åº¦ï¼š{int(progress)}%')
        time.sleep(0.2)

    return progress_bar, progress_text

def get_data_story(chart_config: dict, data: pd.DataFrame, evaluation_score: str) -> str:
    """ç”Ÿæˆæ•°æ®æ•…äº‹"""
    try:
        if data.empty:
            st.warning("æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®æ¥ç”Ÿæˆæ•…äº‹ã€‚")
            return None

        # æ„å»ºæ•°æ®æ¦‚è¦å­—ç¬¦ä¸²
        data_summary = "æ•°æ®åˆ†æç»“æœï¼š\n"
        
        # æ ¹æ®æ•°æ®ç±»å‹æ„å»ºä¸åŒçš„æè¿°
        if 'percentage' in data.columns:
            # åˆ†ç±»æ•°æ®çš„æè¿°
            total_count = data['count'].sum()
            data_summary += f"æ€»è®¡æ ·æœ¬æ•°ï¼š{total_count}\n\n"
            data_summary += "ç±»åˆ«åˆ†å¸ƒï¼š\n"
            for _, row in data.iterrows():
                data_summary += f"- {row['category']}: {row['count']}æ¬¡ (å æ¯”{row['percentage']}%)\n"
        
        elif 'ç»Ÿè®¡æŒ‡æ ‡' in data.columns:
            # æ•°å€¼æ•°æ®çš„æè¿°
            data_summary += "æ•°å€¼ç»Ÿè®¡ï¼š\n"
            for _, row in data.iterrows():
                data_summary += f"- {row['ç»Ÿè®¡æŒ‡æ ‡']}: {row['å€¼']}\n"
        
        else:
            # å…¶ä»–æ•°æ®ç±»å‹çš„æè¿°
            data_summary += data.to_string()

        # æ„å»ºPrompt
        prompt = f"""ä½œä¸ºä¸€åä¸“ä¸šçš„æ•°æ®æ–°é—»è®°è€…ï¼Œè¯·åŸºäºä»¥ä¸‹å›¾è¡¨ä¿¡æ¯æ’°å†™ä¸€æ®µæ•°æ®æ–°é—»æ®µè½ã€‚
å›¾è¡¨ä¿¡æ¯ï¼š
- æ ‡é¢˜ï¼š{chart_config.get('title', '')}
- å›¾è¡¨ç±»å‹ï¼š{chart_config.get('chart_type', '')}
- ä½¿ç”¨æ•°æ®åˆ—ï¼š{', '.join(chart_config.get('columns', []))}
- æ•°æ®æ¥æºï¼š{chart_config.get('source', '')}

{data_summary}

è¦æ±‚ï¼š
1. ä½¿ç”¨ä¸­æ–‡æ•°æ®æ–°é—»ä¸“ä¸šå†™ä½œé£æ ¼
2. çªå‡ºæ•°æ®å‘ç°çš„æ–°é—»ä»·å€¼
3. å®¢è§‚é™ˆè¿°ï¼Œå‡†ç¡®å¼•ç”¨æ•°æ®
4. æ³¨é‡æ•°æ®èƒŒåçš„æ•…äº‹æ€§
5. è¯­è¨€ç®€æ´ä¸“ä¸š"""

        logger.info(f"å‘é€ç»™æ™ºè°±AIçš„Prompt: \n{prompt}")

        # è°ƒç”¨æ™ºè°±AI
        response = client.chat_completions_create(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•°æ®æ–°é—»è®°è€…ï¼Œæ“…é•¿å°†æ•°æ®åˆ†æè½¬åŒ–ä¸ºå¼•äººå…¥èƒœçš„æ–°é—»æ•…äº‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            model="glm-4-plus",
            temperature=0.7
        )

        if 'choices' in response and len(response['choices']) > 0:
            story = response['choices'][0]['message']['content']
            logger.info(f"è·å¾—çš„æ•…äº‹å†…å®¹: {story}")
            return story
        else:
            logger.error("APIå“åº”æ ¼å¼é”™è¯¯")
            st.error("ç”Ÿæˆæ•…äº‹æ—¶å‘ç”Ÿé”™è¯¯ï¼ŒAPIå“åº”æ ¼å¼ä¸æ­£ç¡®ã€‚")
            return None

    except Exception as e:
        logger.error(f"ç”Ÿæˆæ•…äº‹æ—¶å‡ºé”™: {str(e)}")
        st.error(f"ç”Ÿæˆæ•°æ®æ•…äº‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None

def get_data_news_story(selected_charts):
    """åŸºäºå¤šä¸ªé€‰å®šå›¾è¡¨ç”Ÿæˆå®Œæ•´çš„æ•°æ®æ–°é—»æ•…äº‹"""
    if not selected_charts:
        return None
    
    # æ„å»ºæ•°æ®æ¦‚è¦å­—ç¬¦ä¸²
    charts_info = []
    
    for i, chart_info in enumerate(selected_charts):
        config = chart_info['config']
        data = chart_info['data']
        
        chart_summary = f"å›¾è¡¨{i+1}ä¿¡æ¯ï¼š\n"
        chart_summary += f"- æ ‡é¢˜ï¼š{config.get('title', f'å›¾è¡¨{i+1}')}\n"
        chart_summary += f"- å›¾è¡¨ç±»å‹ï¼š{config.get('chart_type', 'è‡ªåŠ¨')}\n"
        chart_summary += f"- ä½¿ç”¨æ•°æ®åˆ—ï¼š{', '.join(config.get('columns', []))}\n"
        chart_summary += f"- æ•°æ®æ¥æºï¼š{config.get('source', 'æœªæŒ‡å®š')}\n\n"
        
        # æ·»åŠ æ•°æ®æè¿°
        chart_summary += "æ•°æ®åˆ†æç»“æœï¼š\n"
        
        if not data.empty:
            # æ ¹æ®æ•°æ®ç±»å‹æ„å»ºä¸åŒçš„æè¿°
            if 'percentage' in data.columns:
                # åˆ†ç±»æ•°æ®çš„æè¿°
                total_count = data['count'].sum()
                chart_summary += f"æ€»è®¡æ ·æœ¬æ•°ï¼š{total_count}\n"
                chart_summary += "ç±»åˆ«åˆ†å¸ƒï¼š\n"
                for _, row in data.head(5).iterrows():
                    chart_summary += f"- {row['category']}: {row['count']}æ¬¡ (å æ¯”{row['percentage']:.2f}%)\n"
                if len(data) > 5:
                    chart_summary += f"- ... ç­‰{len(data)}ä¸ªç±»åˆ«\n"
            
            elif 'ç»Ÿè®¡æŒ‡æ ‡' in data.columns:
                # æ•°å€¼æ•°æ®çš„æè¿°
                chart_summary += "æ•°å€¼ç»Ÿè®¡ï¼š\n"
                for _, row in data.iterrows():
                    chart_summary += f"- {row['ç»Ÿè®¡æŒ‡æ ‡']}: {row['å€¼']}\n"
            
            else:
                # å…¶ä»–æ•°æ®ç±»å‹çš„æè¿°
                chart_summary += "æ•°æ®é¢„è§ˆï¼š\n"
                chart_summary += data.head(3).to_string() + "\n...(æ•°æ®çœç•¥)\n"
        
        charts_info.append(chart_summary)
    
    # æ„å»ºä¼˜åŒ–åçš„Prompt
    prompt = f"""ä½œä¸ºä¸€åä¸“ä¸šæ•°æ®æ–°é—»è®°è€…ï¼Œè¯·åŸºäºä»¥ä¸‹{len(charts_info)}ä¸ªå›¾è¡¨ä¿¡æ¯æ’°å†™ä¸€ç¯‡å®Œæ•´çš„æ•°æ®æ–°é—»æ–‡ç« ã€‚

{"\n\n".join(charts_info)}

éœ€æ±‚ï¼š
1. æ–‡ç« éœ€è¦ä¸€ä¸ªå¸å¼•äººçš„æ ‡é¢˜ï¼Œä½¿ç”¨"# æ ‡é¢˜"æ ¼å¼
2. å°†æ–‡ç« åˆ†æˆ2-4ä¸ªå°èŠ‚ï¼Œæ¯ä¸ªå°èŠ‚æ ‡é¢˜ä½¿ç”¨"### å°èŠ‚æ ‡é¢˜"æ ¼å¼
3. æ–‡ç« ç¯‡å¹…é€‚ä¸­ï¼ˆ400-1100å­—ï¼‰ï¼Œå­—æ•°ä¸å›¾è¡¨æ•°é‡æˆæ­£æ¯”
4. æ–‡ç« é£æ ¼ï¼š
   - å¼€å¤´å¼•å‡ºæ ¸å¿ƒå‘ç°ï¼Œè®¾ç½®æ–°é—»åŸºè°ƒ
   - ä¸­é—´éƒ¨åˆ†æ·±å…¥åˆ†ææ¯ä¸ªå›¾è¡¨æ•°æ®ï¼Œæ­ç¤ºæ•°æ®èƒŒåçš„æ•…äº‹å’Œå…³è”
   - ç»“å°¾æä¾›æ€»ç»“æ€§è§‚ç‚¹æˆ–å»ºè®®
5. è¡¨è¾¾è¦æ±‚ï¼š
   - å®¢è§‚å‡†ç¡®å¼•ç”¨æ•°æ®ï¼Œé¿å…è¿‡åº¦æ¨æµ‹
   - ä½¿ç”¨ä¸“ä¸šä½†é€šä¿—æ˜“æ‡‚çš„è¯­è¨€
   - é€‚å½“è¿ç”¨æ¯”å–»ã€å¯¹æ¯”ç­‰ä¿®è¾æ‰‹æ³•å¢å¼ºå¯è¯»æ€§

è¯·ç›´æ¥è¾“å‡ºå®Œæ•´çš„æ–°é—»æ–‡ç« ï¼Œæ— éœ€è§£é‡Šä½ çš„å†™ä½œè¿‡ç¨‹ã€‚"""

    logger.info(f"å‘é€ç»™æ™ºè°±AIçš„Prompt: \n{prompt}")

    # è°ƒç”¨æ™ºè°±AI
    try:
        response = client.chat_completions_create(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•°æ®æ–°é—»è®°è€…ï¼Œæ“…é•¿å°†å¤šç»´åº¦æ•°æ®åˆ†æè½¬åŒ–ä¸ºå¼•äººå…¥èƒœçš„æ–°é—»æ•…äº‹ã€‚ä½ ä¼šåˆ†æå¤šä¸ªå›¾è¡¨ä¹‹é—´çš„å…³è”ï¼Œæç‚¼å‡ºæ•°æ®èƒŒåçš„æ·±å±‚å«ä¹‰ã€‚"},
                {"role": "user", "content": prompt}
            ],
            model="glm-4-plus",
            temperature=0.7
        )

        if 'choices' in response and len(response['choices']) > 0:
            story = response['choices'][0]['message']['content']
            logger.info(f"è·å¾—çš„æ–°é—»æ•…äº‹å†…å®¹: {story}")
            return story
        else:
            logger.error("APIå“åº”æ ¼å¼é”™è¯¯")
            return None
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ•°æ®æ–°é—»æ—¶å‡ºé”™: {str(e)}")
        return None

# --- æ–°å¢åŠŸèƒ½ï¼šä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ® ---
def extract_structured_from_text(text: str) -> pd.DataFrame:
    """åˆ©ç”¨LLMå°†ç½‘é¡µæ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–æ•°æ®"""
    try:
        prompt = (
            "è¯·ä»ä¸‹é¢çš„æ–°é—»æ–‡æœ¬ä¸­æå–ä¸ç»Ÿè®¡æ•°å­—ç›¸å…³çš„æ•°æ®ï¼Œ"
            "ä»¥CSVæ ¼å¼è¿”å›ï¼Œç¬¬ä¸€è¡Œåº”ä¸ºåˆ—åã€‚\n\n" + text[:2000]
        )
        messages = [
            {"role": "system", "content": "ä½ æ“…é•¿ä»ä¸­æ–‡æ–°é—»æ–‡æœ¬ä¸­æå–è¡¨æ ¼æ•°æ®å¹¶ä»¥CSVå½¢å¼è¾“å‡º"},
            {"role": "user", "content": prompt},
        ]
        response = client.chat_completions_create(messages)
        if 'choices' in response and len(response['choices']) > 0:
            csv_text = response['choices'][0]['message']['content']
            try:
                df = pd.read_csv(StringIO(csv_text))
                return df
            except Exception:
                logger.error("è§£æCSVå¤±è´¥")
                return pd.DataFrame()
    except Exception as e:
        logger.error(f"ç»“æ„åŒ–è§£æå¤±è´¥: {e}")
    return pd.DataFrame()

# è§£ææ¨¡å‹ç”Ÿæˆçš„æ•°æ®æ”¶é›†æ–¹å‘ï¼ŒæŒ‰ç±»åˆ«è¿”å›åˆ—è¡¨
def parse_data_directions(text: str) -> Dict[str, List[str]]:
    """å°†æ•°æ®æ”¶é›†å»ºè®®æ–‡æœ¬è§£æä¸ºç±»åˆ« -> æ–¹å‘åˆ—è¡¨çš„ç»“æ„"""
    sections = re.findall(r"###\s*(.+?)\n(.*?)(?=\n###|$)", text, re.DOTALL)
    result: Dict[str, List[str]] = {}
    for name, content in sections:
        lines = re.findall(r"####\s*(.+)", content)
        if not lines:
            lines = re.findall(r"-\s*(.+)", content)
        if lines:
            result[name.strip()] = [l.strip() for l in lines]
    return result


def generate_questionnaire(directions: List[str]) -> str:
    """è°ƒç”¨æ¨¡å‹ç”Ÿæˆä¸è¶…è¿‡15é¢˜çš„è°ƒç ”é—®å·"""
    prompt = (
        "è¯·æ ¹æ®ä»¥ä¸‹è°ƒç ”æ–¹å‘è®¾è®¡ä¸€ä»½ä¸è¶…è¿‡15é¢˜çš„é—®å·ï¼Œç›´æ¥åˆ—å‡ºé—®é¢˜åˆ—è¡¨ï¼š\n" + "\n".join(directions)
    )
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„é—®å·è®¾è®¡ä¸“å®¶"},
        {"role": "user", "content": prompt},
    ]
    resp = client.chat_completions_create(messages)
    if 'choices' in resp and resp['choices']:
        return resp['choices'][0]['message']['content']
    return "é—®å·ç”Ÿæˆå¤±è´¥"


def generate_crawler_code(directions: List[str]) -> str:
    """æ ¹æ®è‡ªä¸»æ•°æ®æŒ–æ˜éœ€æ±‚ç”Ÿæˆç®€å•çš„çˆ¬è™«ç¤ºä¾‹ä»£ç """
    prompt = (
        "è¯·ä¾æ®ä»¥ä¸‹ç½‘ç«™æ•°æ®æŒ–æ˜éœ€æ±‚ï¼Œæä¾›ä¸€ä¸ªPythonçˆ¬è™«ç¤ºä¾‹ï¼Œä½¿ç”¨requestså’ŒBeautifulSoupï¼Œå°†ç»“æœä¿å­˜ä¸ºCSVï¼š\n"
        + "\n".join(directions)
    )
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€åæ“…é•¿ç¼–å†™ç½‘ç»œçˆ¬è™«çš„Pythonå¼€å‘è€…"},
        {"role": "user", "content": prompt},
    ]
    resp = client.chat_completions_create(messages)
    if 'choices' in resp and resp['choices']:
        return resp['choices'][0]['message']['content']
    return "çˆ¬è™«ä»£ç ç”Ÿæˆå¤±è´¥"

# æ ¹æ®å¤šä¸ªæ•°æ®æ–¹å‘è‡ªåŠ¨æ”¶é›†ç½‘ç»œæ•°æ®å¹¶åˆå¹¶
def collect_data_from_directions(directions: List[str]) -> pd.DataFrame:
    """ä¼˜åŒ–çš„æ•°æ®æ”¶é›†æµç¨‹"""
    if not st.session_state.get('selected_topic'):
        st.error("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ•°æ®æ–°é—»é€‰é¢˜")
        return pd.DataFrame()
    
    topic = st.session_state.selected_topic
    
    # ä½¿ç”¨æ•°æ®æ”¶é›†æ™ºèƒ½ä½“
    agent = DataCollectionAgent(client)
    
    st.info("ğŸ¤– å¯åŠ¨æ™ºèƒ½æ•°æ®æ”¶é›†ä»£ç†...")
    
    # æ‰§è¡Œå¤šç»´åº¦æ•°æ®æ”¶é›†
    collection_results = agent.collect_multi_dimensional_data(directions, topic)
    
    # ä¿å­˜ç»“æ„åŒ–æ•°æ®åˆ—è¡¨åˆ°session state
    if collection_results['structured_data']:
        st.session_state.structured_data_list = collection_results['structured_data']
    
    # æ˜¾ç¤ºæ”¶é›†æ‘˜è¦
    with st.expander("ğŸ“Š æ•°æ®æ”¶é›†æ‘˜è¦", expanded=True):
        for direction, summary in collection_results['collection_summary'].items():
            if direction in collection_results['failed_directions']:
                st.error(f"âŒ {direction}: {summary}")
            else:
                st.success(f"âœ… {direction}: {summary}")
    
    # åˆå¹¶æ‰€æœ‰ç»“æ„åŒ–æ•°æ®
    all_structured_data = collection_results['structured_data']
    
    if all_structured_data:
        try:
            # ä¸ºæ¯ä¸ªæ•°æ®è¡¨åˆ›å»ºç‹¬ç«‹çš„å±•ç¤º
            st.subheader("ğŸ“Š æ”¶é›†åˆ°çš„ç»“æ„åŒ–æ•°æ®")
            
            tabs = st.tabs([f"æ•°æ®è¡¨ {i+1}" for i in range(len(all_structured_data))])
            
            for i, (tab, df) in enumerate(zip(tabs, all_structured_data)):
                with tab:
                    st.write(f"**æ•°æ®æ–¹å‘**: {df.get('data_direction', ['æœªçŸ¥'])[0] if not df.empty and 'data_direction' in df.columns else 'æœªçŸ¥'}")
                    st.write(f"**æ•°æ®æ¥æº**: {df.get('æ•°æ®æ¥æº', ['æœªçŸ¥'])[0] if not df.empty and 'æ•°æ®æ¥æº' in df.columns else 'æœªçŸ¥'}")
                    display_df = df.drop(['data_direction'], axis=1, errors='ignore')
                    st.dataframe(display_df, use_container_width=True)
            
            # æä¾›å¤šSheetä¸‹è½½
            excel_data = export_multi_sheet_data(all_structured_data, topic)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å¤šSheetæ•°æ®è¡¨",
                data=excel_data,
                file_name=f"{topic}_å¤šç»´åº¦æ•°æ®.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
            
            # æ™ºèƒ½åˆå¹¶ä¸åŒç»“æ„çš„æ•°æ®æ¡†
            final_df = smart_merge_dataframes(all_structured_data)
            
            st.success(f"ğŸ‰ æˆåŠŸæ”¶é›†å¹¶ç»“æ„åŒ–äº† {len(all_structured_data)} ä¸ªæ•°æ®é›†ï¼Œåˆå¹¶åå…± {len(final_df)} è¡Œæ•°æ®")
            
            return final_df
            
        except Exception as e:
            st.error(f"æ•°æ®åˆå¹¶å¤±è´¥: {str(e)}")
            logger.error(f"Data merging error: {str(e)}")
    
    # å¦‚æœæ²¡æœ‰ç»“æ„åŒ–æ•°æ®ï¼Œæ˜¾ç¤ºæ–‡æœ¬æ•°æ®
    if collection_results['text_data']:
        st.warning("âš ï¸ æœªèƒ½è·å–åˆ°ç»“æ„åŒ–æ•°æ®ï¼Œä½†æ”¶é›†åˆ°äº†ç›¸å…³æ–‡æœ¬ä¿¡æ¯")
        
        with st.expander("ğŸ“„ æ”¶é›†åˆ°çš„æ–‡æœ¬ä¿¡æ¯", expanded=False):
            for text_data in collection_results['text_data']:
                st.write(f"**æ–¹å‘**: {text_data['direction']}")
                st.write(f"**æ ‡é¢˜**: {text_data['title']}")
                st.write(f"**å†…å®¹**: {text_data['content'][:300]}...")
                st.write(f"**æ¥æº**: {text_data['url']}")
                st.write("---")
    
    return pd.DataFrame()

# æ–°å¢çˆ¬è™«æ•°æ®å¤„ç†ç±»
class WebDataCrawler:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    
    def crawl_data(self, url: str) -> pd.DataFrame:
        """çˆ¬å–ç½‘é¡µæ•°æ®å¹¶è½¬æ¢ä¸ºDataFrame"""
        try:
            st.write(f"å¼€å§‹çˆ¬å–æ•°æ®: {url}")
            progress_bar = st.progress(0)
            
            # å‘é€è¯·æ±‚è·å–é¡µé¢å†…å®¹
            response = requests.get(url, headers=self.headers, timeout=30)
            response.raise_for_status()
            
            progress_bar.progress(0.5)
            
            # å°è¯•æå–è¡¨æ ¼æ•°æ®
            tables = pd.read_html(response.text)
            if tables:
                df = tables[0]  # è·å–ç¬¬ä¸€ä¸ªè¡¨æ ¼
                # ä¿å­˜åˆ°session state
                st.session_state['crawled_df'] = df
                st.write("æ•°æ®é¢„è§ˆï¼š")
                st.write(df.head())
                progress_bar.progress(1.0)
                return df
            
            # å¦‚æœæ²¡æœ‰è¡¨æ ¼ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ç»“æ„åŒ–æ•°æ®
            soup = BeautifulSoup(response.text, 'html.parser')
            text_content = soup.get_text()
            df = extract_structured_from_text(text_content)
            if df is None or df.empty:
                df = pd.DataFrame({
                    'content': [text_content],
                    'url': [url],
                    'timestamp': [pd.Timestamp.now()]
                })
            st.session_state['crawled_df'] = df
            progress_bar.progress(1.0)
            st.write("è·å–åˆ°çš„æ–‡æœ¬æ•°æ®é¢„è§ˆï¼š")
            st.write(text_content[:500] + "...")
            return df
            
        except Exception as e:
            msg = getattr(e, 'response', None)
            if msg is not None:
                err_detail = f"{msg.status_code} {msg.reason}"
            else:
                err_detail = str(e)
            st.error(f"çˆ¬å–å¤±è´¥: {err_detail}")
            logger.error(f"çˆ¬å–å¤±è´¥: {err_detail}")
            return pd.DataFrame()

# Main Application
def main():
    # åˆå§‹åŒ–session stateå˜é‡
    if 'selected_charts' not in st.session_state:
        st.session_state.selected_charts = []
    
    st.title("å¤æ–°Vis-æ•°æ®æ–°é—»å¤šæ™ºèƒ½ä½“å·¥ä½œæµ")
    
    # ä½¿ç”¨çº¯ç™½è‰²èƒŒæ™¯ï¼Œåªä¿ç•™ä»‹ç»æ–‡å­—çš„æ ·å¼
    st.markdown(
        """
        <style>
        .intro-text {
            padding: 20px;
            border-radius: 10px;
            background-color: rgba(255, 255, 255, 0.9);
            margin: 20px 0;
        }
        
        .intro-point {
            margin: 10px 0;
            padding-left: 20px;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # å§‹ç»ˆæ˜¾ç¤ºä¾§è¾¹æ 
    with st.sidebar:
        st.header("å½“ä½ å‡†å¤‡å¥½äº†ï¼Œä½ å¯ä»¥å¼€å§‹æ•°æ®è¾“å…¥")
        data_input_method = st.radio(
            "é€‰æ‹©æ•°æ®è¾“å…¥æ–¹å¼",
            ["ä¸Šä¼ æ–‡ä»¶", "ç½‘é¡µçˆ¬å–"]
        )
        
        if data_input_method == "ä¸Šä¼ æ–‡ä»¶":
            uploaded_file = st.file_uploader("ä¸Šä¼  CSVã€Excel æˆ– JSON æ–‡ä»¶", 
                                           type=['csv', 'xlsx', 'xls', 'json'])
            if uploaded_file:
                processor = DataProcessor(uploaded_file)
                # ä¿å­˜åˆ°session state
                st.session_state['current_processor'] = processor
                # è®¾ç½®çŠ¶æ€ï¼Œè¡¨ç¤ºå·²ä¸Šä¼ æ•°æ®
                st.session_state['data_uploaded'] = True
                
        else:  # ç½‘é¡µçˆ¬å–
            url = st.text_input("è¾“å…¥è¦çˆ¬å–çš„ç½‘é¡µURL")
            
            with st.expander("çˆ¬å–é…ç½®"):
                timeout = st.slider("è¶…æ—¶æ—¶é—´(ç§’)", 10, 60, 30)
            
            if st.button("å¼€å§‹çˆ¬å–", key="crawl_button"):
                if url:
                    try:
                        crawler = WebDataCrawler()
                        df = crawler.crawl_data(url)
                        
                        if not df.empty:
                            processor = DataProcessor(df)
                            # ä¿å­˜åˆ°session state
                            st.session_state['current_processor'] = processor
                            # è®¾ç½®çŠ¶æ€ï¼Œè¡¨ç¤ºå·²ä¸Šä¼ æ•°æ®
                            st.session_state['data_uploaded'] = True
                            st.success("æ•°æ®çˆ¬å–æˆåŠŸï¼")
                        else:
                            st.warning("æœªè·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥URLæˆ–å°è¯•å…¶ä»–ç½‘é¡µã€‚")
                    except Exception as e:
                        st.error(f"çˆ¬å–å¤±è´¥: {str(e)}")

    # ä»session stateè·å–processor
    processor = st.session_state.get('current_processor', None)
    
    # å¦‚æœæ•°æ®æœªä¸Šä¼ ä¸”æœªè·³è¿‡é€‰é¢˜é˜¶æ®µï¼Œåˆ™æ˜¾ç¤ºé€‰é¢˜å’Œæ•°æ®æ”¶é›†ç•Œé¢
    if not st.session_state.get('data_uploaded', False):
        # ç¬¬ä¸€é˜¶æ®µï¼šé€‰é¢˜ç¡®å®š
        if not topic_selection_phase():
            return  # å¦‚æœè¿˜æ²¡å®Œæˆé€‰é¢˜ç¡®å®šï¼Œä¸è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
        
        # ç¬¬äºŒé˜¶æ®µï¼šæ•°æ®æ”¶é›†æ–¹å‘
        if not data_collection_phase():
            return  # å¦‚æœè¿˜æ²¡å®Œæˆæ•°æ®æ”¶é›†æ–¹å‘ç”Ÿæˆï¼Œä¸è¿›å…¥ä¸‹ä¸€é˜¶æ®µ
            
        # å¦‚æœä»ç„¶æ²¡æœ‰æ•°æ®ï¼Œæ˜¾ç¤ºä»‹ç»å†…å®¹
        if not processor or processor.df is None:
            st.markdown(
                """
                <div class="intro-text">
                    <h3>æ¥ä¸‹æ¥çš„å·¥ä½œæµç¨‹ï¼ˆç‰ˆæœ¬0226ï¼‰</h3>
                    <div class="intro-point">ğŸ“Š <b>é¦–å…ˆï¼Œä¸Šä¼ ä½ çš„æ•°æ®ï¼š</b>æ”¯æŒä¸Šä¼ æœ¬åœ°æ•°æ®é›†æˆ–ä½¿ç”¨æˆ‘ä»¬çš„ç½‘é¡µæ•°æ®çˆ¬å–</div>
                    <div class="intro-point">ğŸ¤– <b>ç„¶åï¼Œè·å–å¯è§†åŒ–çš„å»ºè®®ï¼š</b>å¤§æ¨¡å‹ä¼šåŸºäºæ•°æ®ç‰¹å¾æä¾›ä¸“ä¸šçš„å¯è§†åŒ–å»ºè®®</div>
                    <div class="intro-point">ğŸ“ˆ <b>å…¶æ¬¡ï¼Œåˆ¶ä½œå¯è§†åŒ–å›¾è¡¨ï¼š</b>æä¾›å¤šç§å›¾è¡¨ç±»å‹å’Œæ¼‚äº®çš„é…è‰²é€‰æ‹©</div>
                    <div class="intro-point">ğŸ“ <b>æœ€åï¼Œæ‹¿ä¸Šè¯„ä¼°åˆæ ¼çš„å›¾è¡¨ï¼Œæ’°å†™å‡ºæ•°æ®æ•…äº‹ï¼š</b>è‡ªåŠ¨ç”Ÿæˆä¸“ä¸šåª’ä½“é£æ ¼çš„æ•°æ®æ–°é—»æ®µè½</div>
                </div>
                """,
                unsafe_allow_html=True
            )
            return
    
    # å¦‚æœä¸Šä¼ äº†æ•°æ®ï¼Œæ˜¾ç¤ºæ•°æ®å¤„ç†å’Œå¯è§†åŒ–ç•Œé¢
    if processor and processor.df is not None:
        # å¦‚æœä¹‹å‰å®Œæˆäº†é€‰é¢˜é˜¶æ®µï¼Œæ˜¾ç¤ºé€‰é¢˜ä¿¡æ¯
        if st.session_state.get('selected_topic') and not st.session_state.get('skip_topic_selection'):
            with st.expander("å·²é€‰å®šçš„é€‰é¢˜", expanded=False):
                st.success(f"æ•°æ®æ–°é—»é€‰é¢˜ï¼š{st.session_state.selected_topic}")
                if st.session_state.get('data_directions'):
                    st.markdown(st.session_state.data_directions)
        
        # 1. æ•°æ®é¢„è§ˆéƒ¨åˆ† - é»˜è®¤å±•å¼€
        with st.expander("æ•°æ®é¢„è§ˆ", expanded=True):
            st.dataframe(processor.df.head(31), use_container_width=True)

        # 2. æ•°æ®å¯è§†åŒ–å»ºè®®éƒ¨åˆ†
        st.subheader("ç¬¬ä¸‰æ­¥ï¼Œè·å–æ•°æ®å¯è§†åŒ–å»ºè®®")
        suggestion_container = st.container()
        with suggestion_container:
            if st.button("è·å–å¯è§†åŒ–å»ºè®®", key="viz_suggestion_btn"):
                progress_bar, progress_text = simulate_progress_bar()

                response = get_llm_response("è¯·ä¸ºè¿™ä¸ªæ•°æ®é›†æä¾›å¯è§†åŒ–å»ºè®®", processor.df)

                # å®Œæˆæ—¶å°†è¿›åº¦è®¾ä¸º100%
                progress_bar.progress(100)
                progress_text.text('åˆ†æå®Œæˆï¼')
                time.sleep(0.5)  # çŸ­æš‚æ˜¾ç¤ºå®ŒæˆçŠ¶æ€

                progress_bar.empty()
                progress_text.empty()

                if response:
                    st.session_state.visualization_suggestions = response
                    st.markdown(response, unsafe_allow_html=True)

            elif st.session_state.get('visualization_suggestions'):
                st.markdown(st.session_state.visualization_suggestions, unsafe_allow_html=True)

        # 3. å¯è§†åŒ–åˆ¶ä½œéƒ¨åˆ†
        st.subheader("ç¬¬å››æ­¥ï¼Œåˆ›å»ºå¯è§†åŒ–")
        col1, col2 = st.columns([1, 2])

        with col1:
            # æ·»åŠ ä¸»é¢˜é€‰æ‹©
            color_theme = st.selectbox(
                "é€‰æ‹©é…è‰²ä¸»é¢˜",
                options=['modern', 'nyt', 'soft'],
                format_func=lambda x: {
                    'modern': 'ç°ä»£ç®€çº¦',
                    'nyt': 'æ–°é—»ä¸“ä¸š',
                    'soft': 'æŸ”å’Œæ¸…æ–°'
                }[x]
            )

            show_legend = st.checkbox("æ˜¾ç¤ºå›¾ä¾‹", value=True)

            viz_type = st.radio(
                "é€‰æ‹©åˆ†æç±»å‹",
                options=['å•åˆ—åˆ†æ', 'åŒåˆ—å…³ç³»åˆ†æ'],
                horizontal=True
            )

            custom_title = st.text_input("è¾“å…¥å›¾è¡¨æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰", "")
            data_source = st.text_input("è¾“å…¥æ•°æ®æ¥æºï¼ˆå¯é€‰ï¼‰", "")

            if viz_type == 'å•åˆ—åˆ†æ':
                column = st.selectbox("é€‰æ‹©è¦åˆ†æçš„åˆ—", options=processor.df.columns)
                chart_type = st.radio(
                    "é€‰æ‹©å›¾è¡¨ç±»å‹",
                    options=['è‡ªåŠ¨', 'é¥¼å›¾', 'æŸ±çŠ¶å›¾', 'ç›´æ–¹å›¾', 'ç®±çº¿å›¾', 'å°æç´å›¾', 'æ ‘å›¾', 'æ—­æ—¥å›¾'],
                    horizontal=True
                )
                columns_to_use = [column]
            else:
                x_column = st.selectbox("é€‰æ‹© X è½´æ•°æ®", options=processor.df.columns)
                y_column = st.selectbox("é€‰æ‹© Y è½´æ•°æ®", options=processor.df.columns)
                chart_type = st.radio(
                    "é€‰æ‹©å›¾è¡¨ç±»å‹",
                    options=['è‡ªåŠ¨', 'æŠ˜çº¿å›¾', 'æŸ±çŠ¶å›¾', 'æ•£ç‚¹å›¾', 'ç®±çº¿å›¾', 'å°æç´å›¾', 'çƒ­åŠ›å›¾'],
                    horizontal=True
                )
                columns_to_use = [x_column, y_column]

            if st.button("ç”Ÿæˆå›¾è¡¨"):
                # æ¯æ¬¡ç”Ÿæˆæ–°å›¾è¡¨æ—¶ï¼Œæ¸…é™¤ä¹‹å‰çš„æ•°æ®æ•…äº‹
                if 'data_story' in st.session_state:
                    del st.session_state['data_story']
                
                st.session_state.show_legend = show_legend

                st.session_state.current_chart_config = {
                    'viz_type': viz_type,
                    'columns': columns_to_use,
                    'chart_type': chart_type,
                    'title': custom_title,
                    'source': data_source
                }

        with col2:
            if 'current_chart_config' in st.session_state:
                config = st.session_state.current_chart_config
                vis_gen = VisualizationGenerator(processor.df)
                vis_gen.set_theme(color_theme)  # è®¾ç½®é€‰æ‹©çš„ä¸»é¢˜

                # è½¬æ¢è‹±æ–‡å›¾è¡¨ç±»å‹ä¸ºä¸­æ–‡
                chart_type_map = {
                    'è‡ªåŠ¨': 'auto',
                    'é¥¼å›¾': 'pie',
                    'æŸ±çŠ¶å›¾': 'bar',
                    'ç›´æ–¹å›¾': 'histogram',
                    'æŠ˜çº¿å›¾': 'line',
                    'æ•£ç‚¹å›¾': 'scatter',
                    'ç®±çº¿å›¾': 'box',
                    'å°æç´å›¾': 'violin',
                    'æ ‘å›¾': 'treemap',
                    'æ—­æ—¥å›¾': 'sunburst'
                }

                chart_type = chart_type_map.get(config['chart_type'], config['chart_type'])

                chart = vis_gen.generate_chart(
                    columns=config['columns'],
                    chart_type=chart_type,
                    title=config['title'],
                    source=config['source'],
                    show_legend=st.session_state.get('show_legend', True)  # è·å–å›¾ä¾‹æ˜¾ç¤ºçŠ¶æ€
                )

                if chart:
                    # ä¿®æ”¹ï¼šä½¿ç”¨st_pyechartsæ˜¾ç¤ºEChartså›¾è¡¨ï¼Œè€Œä¸æ˜¯st.plotly_chart
                    st_pyecharts(chart, height="500px")

                    with st.expander("å›¾è¡¨è¯„ä¼°ç»“æœï¼ˆå¯¹å›¾è¡¨ç‚¹å‡»å³é”®å¯ä¿å­˜ä¸ºå›¾ç‰‡ï¼‰", expanded=True):
                        score, dimensions, feedback = vis_gen.evaluate_chart(
                            chart_type,
                            config['columns']
                        )
                        st.write(f"**å›¾è¡¨è¯„ä¼°å¾—åˆ†:** {score}")
                        st.write("**è¯„ä¼°ç»´åº¦:**")
                        for dim in dimensions:
                            st.write(f"- {dim}")
                        st.write(f"**è¯„ä¼°å»ºè®®:** {feedback}")

                        # ç§»é™¤åŸæœ‰çš„æ•…äº‹ç”ŸæˆæŒ‰é’®ï¼Œæ›¿æ¢ä¸ºé€‰å®šæŒ‰é’®
                        if score in ["åŸºæœ¬é€‚åˆ", "éå¸¸é€‚åˆ"]:
                            if st.button("é€‰å®šæ­¤å›¾è¡¨"):
                                # æ£€æŸ¥æ˜¯å¦å·²ç»é€‰å®šäº†5ä¸ªå›¾è¡¨
                                if len(st.session_state.selected_charts) >= 5:
                                    st.warning("æœ€å¤šåªèƒ½é€‰å®š5ä¸ªå›¾è¡¨ï¼è¯·å…ˆåˆ é™¤ä¸€äº›å·²é€‰å®šçš„å›¾è¡¨ã€‚")
                                else:
                                    # å°†å½“å‰å›¾è¡¨é…ç½®å’Œæ•°æ®æ·»åŠ åˆ°å·²é€‰å®šå›¾è¡¨åˆ—è¡¨
                                    chart_data = vis_gen.get_chart_data(config['columns'])
                                    # ä¿å­˜å›¾è¡¨é…ç½®ã€æ•°æ®å’Œè¯„ä¼°ä¿¡æ¯
                                    chart_info = {
                                        'config': config.copy(),
                                        'data': chart_data,
                                        'score': score,
                                        'chart': chart  # ä¿å­˜å›¾è¡¨å¯¹è±¡
                                    }
                                    st.session_state.selected_charts.append(chart_info)
                                    st.success(f"å·²é€‰å®šå›¾è¡¨ï¼Œå½“å‰å·²é€‰å®š {len(st.session_state.selected_charts)} ä¸ªå›¾è¡¨")

    # æ˜¾ç¤ºå·²é€‰å®šçš„å›¾è¡¨å’Œç¬¬ä¸‰æ­¥ç”Ÿæˆæ•°æ®æ–°é—»
    if processor and processor.df is not None:  # ç¡®ä¿æœ‰æ•°æ®è¢«åŠ è½½åæ‰æ‰§è¡Œ
        if 'selected_charts' in st.session_state and st.session_state.selected_charts:
            st.subheader("å·²é€‰å®šçš„å›¾è¡¨")
            # ä½¿ç”¨åˆ—è¡¨å®¹å™¨å±•ç¤ºå·²é€‰å›¾è¡¨
            for i, chart_info in enumerate(st.session_state.selected_charts):
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.write(f"**å›¾è¡¨ {i+1}**: {chart_info['config'].get('title', 'æœªå‘½åå›¾è¡¨')}")
                    # æ˜¾ç¤ºå›¾è¡¨
                    st_pyecharts(chart_info['chart'], height="300px")
                
                with col2:
                    st.write(f"è¯„ä¼°: {chart_info['score']}")
                    # æ·»åŠ åˆ é™¤æŒ‰é’®
                    if st.button(f"åˆ é™¤æ­¤å›¾è¡¨", key=f"del_chart_{i}"):
                        st.session_state.selected_charts.pop(i)
                        st.rerun()
            
            # ç¬¬ä¸‰æ­¥ - ç”Ÿæˆå®Œæ•´æ•°æ®æ–°é—»
            st.subheader("ç¬¬äº”æ­¥ï¼Œå†™ä½œæ•°æ®æ•…äº‹")
            
            if st.button("ç”Ÿæˆå®Œæ•´æ•°æ®æ–°é—»"):
                progress_bar = st.progress(0)
                progress_text = st.empty()
                
                # æ¨¡æ‹Ÿè¿›åº¦
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    if i == 0:
                        progress_text.text("åˆå§‹åŒ–æ•°æ®åˆ†æ...")
                    elif i == 20:
                        progress_text.text("æå–æ•°æ®å…³é”®ç‚¹...")
                    elif i == 40:
                        progress_text.text("æ„å»ºæ–°é—»æ•…äº‹æ¶æ„...")
                    elif i == 60:
                        progress_text.text("ç”Ÿæˆæ–°é—»å†…å®¹...")
                    elif i == 80:
                        progress_text.text("æ¶¦è‰²æ–‡ç« è¡¨è¾¾...")
                    time.sleep(1.7)
                
                # å®é™…ç”Ÿæˆæ•°æ®æ–°é—»
                story = get_data_news_story(st.session_state.selected_charts)
                
                # å®Œæˆè¿›åº¦
                progress_bar.progress(100)
                progress_text.text("æ•°æ®æ–°é—»ç”Ÿæˆå®Œæˆï¼")
                time.sleep(0.5)
                
                # æ¸…é™¤è¿›åº¦æ¡å’Œæ–‡æœ¬
                progress_bar.empty()
                progress_text.empty()
                
                if story:
                    st.session_state.news_story = story
                else:
                    st.error("æ— æ³•ç”Ÿæˆæ•°æ®æ–°é—»ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            
            # æ˜¾ç¤ºæ•°æ®æ–°é—»
            if 'news_story' in st.session_state:
                # è®¾è®¡ä¸€ä¸ªå¯Œåª’ä½“æ¡†æ¥å±•ç¤ºæ–°é—»å†…å®¹
                st.markdown(
                    """
                    <style>
                    .news-container {
                        padding: 20px;
                        background-color: #f8f9fa;
                        border-radius: 10px;
                        border-left: 5px solid #4A90E2;
                        margin: 10px 0;
                    }
                    .news-title {
                        font-size: 24px;
                        font-weight: bold;
                        margin-bottom: 15px;
                        color: #2c3e50;
                    }
                    .news-section {
                        font-size: 18px;
                        font-weight: bold;
                        margin: 15px 0 10px 0;
                        color: #3498db;
                    }
                    .news-content {
                        font-size: 16px;
                        line-height: 1.6;
                        color: #333;
                    }
                    </style>
                    """,
                    unsafe_allow_html=True
                )
                
                # å¤„ç†Markdownæ ¼å¼çš„æ–°é—»å†…å®¹
                news_content = st.session_state.news_story
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ ‡é¢˜å’Œå°èŠ‚æ ‡é¢˜
                # å‡è®¾æœ€å¤§çš„æ ‡é¢˜ä½¿ç”¨# æˆ–## å¼€å§‹ï¼Œå°èŠ‚æ ‡é¢˜ä½¿ç”¨### å¼€å§‹
                title_match = re.search(r'^#\s+(.+)$|^##\s+(.+)$', news_content, re.MULTILINE)
                if title_match:
                    title = title_match.group(1) if title_match.group(1) else title_match.group(2)
                    # ä»å†…å®¹ä¸­ç§»é™¤ä¸»æ ‡é¢˜
                    news_content = re.sub(r'^#\s+.+$|^##\s+.+$', '', news_content, count=1, flags=re.MULTILINE)
                else:
                    title = "æ•°æ®æ–°é—»æŠ¥é“"
                
                # æŸ¥æ‰¾æ‰€æœ‰å°èŠ‚æ ‡é¢˜å’Œå†…å®¹
                sections = re.split(r'^###\s+(.+)$', news_content, flags=re.MULTILINE)
                
                # æ˜¾ç¤ºå¯Œåª’ä½“æ ¼å¼çš„æ–°é—»
                news_html = f'<div class="news-container"><div class="news-title">{title}</div>'
                
                if len(sections) > 1:  # æœ‰å°èŠ‚æ ‡é¢˜
                    for i in range(1, len(sections), 2):
                        if i < len(sections):
                            section_title = sections[i]
                            section_content = sections[i + 1] if i + 1 < len(sections) else ""
                            news_html += f'<div class="news-section">{section_title}</div>'
                            news_html += f'<div class="news-content">{section_content}</div>'
                else:  # æ²¡æœ‰å°èŠ‚æ ‡é¢˜ï¼Œç›´æ¥æ˜¾ç¤ºå†…å®¹
                    news_html += f'<div class="news-content">{news_content}</div>'
                
                news_html += '</div>'
                st.markdown(news_html, unsafe_allow_html=True)
                
                # æä¾›ä¸‹è½½æŒ‰é’®
                col1, col2 = st.columns(2)
                with col1:
                    st.download_button(
                        label="ä¸‹è½½Markdownæ ¼å¼",
                        data=st.session_state.news_story,
                        file_name="data_news_story.md",
                        mime="text/markdown"
                    )
                with col2:
                    word_file = export_to_word(st.session_state.news_story)
                    st.download_button(
                        label="ä¸‹è½½Wordæ–‡æ¡£",
                        data=word_file,
                        file_name="data_news_story.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                
                # æ·»åŠ æ•°æ®å¯¼å‡ºåŠŸèƒ½
                if 'current_processor' in st.session_state and hasattr(st.session_state.current_processor, 'df'):
                    st.subheader("æ•°æ®å¯¼å‡º")
                    col3, col4 = st.columns(2)
                    
                    with col3:
                        # å¯¼å‡ºå½“å‰æ•°æ®é›†
                        csv_data = st.session_state.current_processor.df.to_csv(index=False)
                        st.download_button(
                            label="ä¸‹è½½å½“å‰æ•°æ®é›†(CSV)",
                            data=csv_data,
                            file_name="current_dataset.csv",
                            mime="text/csv"
                        )
                    
                    with col4:
                        # å¦‚æœæœ‰å¤šä¸ªç»“æ„åŒ–æ•°æ®é›†ï¼Œæä¾›å¤šSheet Excelä¸‹è½½
                        if hasattr(st.session_state, 'structured_data_list') and st.session_state.structured_data_list:
                            excel_file = export_multi_sheet_data(
                                st.session_state.structured_data_list, 
                                st.session_state.get('selected_topic', 'æ•°æ®åˆ†æ')
                            )
                            st.download_button(
                                label="ä¸‹è½½å¤šSheetæ•°æ®(Excel)",
                                data=excel_file,
                                file_name="multi_sheet_data.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
        elif processor and processor.df is not None:  # åªåœ¨æœ‰æ•°æ®ä½†æ²¡æœ‰é€‰å®šå›¾è¡¨æ—¶æ˜¾ç¤ºæç¤º
            st.info("è¯·å…ˆé€‰å®šè‡³å°‘ä¸€ä¸ªå›¾è¡¨ï¼Œæ‰èƒ½ç”Ÿæˆæ•°æ®æ–°é—»ã€‚")

def export_multi_sheet_data(structured_data_list: List[pd.DataFrame], topic: str):
    """å¯¼å‡ºå¤šSheet Excelæ–‡ä»¶"""
    output = BytesIO()
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        sheet_names = set()
        
        for i, df in enumerate(structured_data_list):
            # æ ¹æ®æ•°æ®æ–¹å‘ç”ŸæˆSheetåç§°
            direction = df.get('data_direction', [f'æ•°æ®{i+1}'])[0] if not df.empty else f'æ•°æ®{i+1}'
            sheet_name = direction[:30]  # Excel sheetåç§°é™åˆ¶
            
            # ç¡®ä¿Sheetåç§°å”¯ä¸€
            original_name = sheet_name
            counter = 1
            while sheet_name in sheet_names:
                sheet_name = f"{original_name}_{counter}"
                counter += 1
            
            sheet_names.add(sheet_name)
            df.to_excel(writer, sheet_name=sheet_name, index=False)
    
    output.seek(0)
    return output

def export_to_word(news_content, selected_charts=None):
    """å°†æ–°é—»å†…å®¹å¯¼å‡ºä¸ºWordæ–‡æ¡£"""
    doc = Document()
    
    # å¤„ç†Markdownå†…å®¹
    # æå–ä¸»æ ‡é¢˜
    title_match = re.search(r'^#\s+(.+)$|^##\s+(.+)$', news_content, re.MULTILINE)
    if title_match:
        title = title_match.group(1) if title_match.group(1) else title_match.group(2)
        doc.add_heading(title, level=0)
        # ä»å†…å®¹ä¸­ç§»é™¤ä¸»æ ‡é¢˜
        news_content = re.sub(r'^#\s+.+$|^##\s+.+$', '', news_content, count=1, flags=re.MULTILINE)
    
    # å¤„ç†å°èŠ‚æ ‡é¢˜å’Œå†…å®¹
    sections = re.split(r'^###\s+(.+)$', news_content, flags=re.MULTILINE)
    
    # å¦‚æœæœ‰å°èŠ‚
    if len(sections) > 1:
        # å¤„ç†ç¬¬ä¸€ä¸ªéæ ‡é¢˜éƒ¨åˆ†(å¦‚æœæœ‰çš„è¯)
        if sections[0].strip():
            doc.add_paragraph(sections[0].strip())
            
        # å¤„ç†å„å°èŠ‚
        for i in range(1, len(sections), 2):
            if i < len(sections):
                section_title = sections[i]
                section_content = sections[i + 1] if i + 1 < len(sections) else ""
                
                # æ·»åŠ å°èŠ‚æ ‡é¢˜
                doc.add_heading(section_title, level=2)
                
                # æ·»åŠ å°èŠ‚å†…å®¹
                doc.add_paragraph(section_content.strip())
    else:
        # æ²¡æœ‰å°èŠ‚ï¼Œç›´æ¥æ·»åŠ å†…å®¹
        doc.add_paragraph(news_content.strip())
    
    # ä¿å­˜Wordæ–‡æ¡£åˆ°å†…å­˜
    doc_io = BytesIO()
    doc.save(doc_io)
    doc_io.seek(0)
    
    return doc_io

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"Application error: {str(e)}")
        logger.error(f"Application error: {str(e)}")
